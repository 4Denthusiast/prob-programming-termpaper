% !TEX root = ./probabilisticProgrammingMartingales.tex

\begin{proof}
If $T$ is bounded by $b$ a.s.~(for $n$ constant), the statement is trivially true by taking $\epsilon$ to be constantly 1, and $Y_n = b - n$.
Otherwise, let $(t_n)_{n \geq 0}$ be defined recursively such that $t_0 = 0$, $t_{n+1} > t_n$ and $\mathbb P[T > t_{n+1}] \leq \frac 1 4 \mathbb P[T > t_n]$.
We will then define a supermartingale $(Y_n)_{n \geq 0}$ and nonrandom sequence $(y_n)_{n \geq 0}$ such that $Y_n = 0$ iff $T < n$, $Y_n = y_n$ iff $T \geq n$, and $y_n \geq 2^k$ for $n \geq t_k$.

The antitone function $\epsilon$ is defined piecewise and recursively in such a way as to force all the necessary constraints to hold:
\begin{align*}
    \text{for }x \in [0,1),\ &\epsilon(x) = 1 \\
    \text{for }x \in [2^k,2^{k+1}),\ &\epsilon(x) = \min \left (\epsilon(2^{k-1}), \frac{2^k}{t_{k+1}-t_k} \right ).
\end{align*}
This ensures that
\begin{itemize}
\item $\epsilon$ is weakly decreasing. 
\item $\epsilon$ is bounded below by 0.
\item For $x \geq 2^k$, $\epsilon(x) \leq \frac{2^k}{t_{k+1}-t_k}$. 
\lo{This would imply $\frac{2^k}{t_{k+1}-t_k} \geq \epsilon(2^{k-1})$. Why?} \akr{Corrected: it should have been min, not max.}
\end{itemize}

The sequence $(y_n)_{n \geq 0}$ is then defined recursively by
\begin{align*}
    y_0 = 2, \quad
    y_{n+1} = (y_n - \epsilon(y_n)) \frac{\mathbb P[T > n]}{\mathbb P[T > n+1]}.
\end{align*}

The fact $y_{t_k} \geq 2^{k+1}$ is proven by induction on $k$. For base case, $2 \geq 2$, as required. For the inductive case $k+1$, we first do another induction to prove that $y_n \geq 2^k$ for all $t_k \leq n \leq t_{k+1}$. The base case of this inner induction follows from the outer induction hypothesis a fortiori. Take the greatest $k$ such that $n > t_k$. By the induction hypothesis, $y_{t_k} \geq 2^k$.
\begin{align*}
    y_n & = y_{t_k} \frac{\mathbb P[T > t_k]}{\mathbb P[T > n]} - \sum_{m=t_k}^{n-1} \epsilon(y_m) \frac{\mathbb P[T > m+1]}{\mathbb P[T > n]} \\
    & \geq \frac{\mathbb P[T > t_k]}{\mathbb P[T > n]} (y_{t_k} - \sum_{m=t_k}^{n-1} \epsilon(y_m)) \\
    & \geq \frac{\mathbb P[T > t_k]}{\mathbb P[T > n]} (y_{t_k} - \sum_{m=t_k}^{n-1} \frac{2^k}{t_{k+1}-t_k}) \\
    & = \frac{\mathbb P[T > t_k]}{\mathbb P[T > n]} (y_{t_k} - \frac{2^k (n - t_k)}{t_{k+1}-t_k}) \\
    & \geq \frac{\mathbb P[T > t_k]}{\mathbb P[T > n]} (y_{t_k} - 2^k) \\
    & \geq \frac{\mathbb P[T > t_k]}{\mathbb P[T > n]} (2^{k+1} - 2^k) \\
    & = \frac{\mathbb P[T > t_k]}{\mathbb P[T > n]} 2^k \\
    & \geq 2^k
\end{align*}
as required. Substituting $n = t_{k+1}$ and using the fact that $\frac{\mathbb P[T > t_k]}{\mathbb P[T > t_{k+1}]} > 4$, the same reasoning gives $y_{t_{k+1}} \geq 2^{k+2}$, as required.

Although the stronger induction hypothesis was necessary for the induction to work, the only reason this is needed is to prove that $y_n > 0$ for all $n$, which implies that $Y_n \geq 0$. 
The other condition for $(Y_n)$ to be an antitone-strict supermartingale is
\begin{align*}
    & \expect{Y_{n+1} \mid \mathcal F_n} \\
    = & \expect{y_{n+1} \, 1_{\set{T \geq n+1}} \mid \mathcal F_n} \\
    = & y_{n+1} \, \expect{1_{\set{T \geq n+1}} \mid \mathcal F_n} \\ 
    = & y_{n+1} \, 1_{\set{T \geq n}} \frac{\mathbb P[T > n+1]}{\mathbb P[T > n]} \\
    = & (y_n - \epsilon(y_n)) \, 1_{\set{T \geq n}} \\
    = & Y_n - \epsilon(y_n) \, 1_{\set{T \geq n}}
\end{align*}
therefore $(Y_n)_n$ is an antitone strict supermartingale with respect to $(T,\epsilon)$.
\end{proof}

The assumption that $(\mathcal F_n)_{n \geq 0}$ is the coarsest filtration to which $T$ is adapted is used in the equality between the third and fourth lines here. This condition is the main reason that this proof does not extend directly to a completeness result for antitone ranking functions.

