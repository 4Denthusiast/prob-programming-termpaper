% !TEX root = main.tex
\section{Supermartingales}
\label{sec:supermartingales}

One approach to proving that a term terminates almost surely is to find some variant that is bounded below and, on average, decreases sufficiently quickly that it must eventually reach 0, similarly to the approach taken by 
%\citep{DBLP:journals/pacmpl/McIverMKK18} 
\cite{DBLP:conf/popl/FioritiH15} and others for imperative programs.

These variants are defined as functions from reachable terms (i.e.~possible states of the program's execution) to real numbers. Specifically, let the set of reachable terms from a given closed starting term $M$ be $Rch(M) := \{N \in \Lambda \mid M \to^* N \}$, with the $\sigma$-algebra induced as a subset of $\Lambda$.

\begin{definition}\rm
A \emph{ranking function on $M \in \Lambda^0$} is a measurable function $f:\mathit{Rch}(M) \to \mathbb{R}$ such that $f(N) \geq 0$ for all $N$, and
\begin{enumerate}
    \item $f(E[\tY \lambda x. N]) \geq 1+ f(E[\lambda z. N[(\tY \lambda x. N)/x] z)$ where $z$ is not free in $N$
    \item $f(E[\tsample]) \geq \int_I f(E[\underline{x}]) \, \Leb(\mathrm{d}x)$
    \item $f(E[R]) \geq f(E[R'])$ for any other redex $R$, where $R \to R'$.
\end{enumerate}
\lo{@Andrew: As defined, ranking function $f$ is not required to satisfy: $f(N) = 0$ iff $N$ is a value.
But for AST analysis, we always require $f$ to satisfy this property.
It seems cleaner to include this in the definition.}
We say that the ranking function $f$ is \emph{strict} if there exists $\epsilon > 0$ such that $f(N) = 0$ iff $N$ is a value; and for all $E$ and $R \to R'$, $f(E[R']) \leq f(E[R]) - \epsilon$.

Any closed term for which a ranking (respectively, strict ranking) function exists is called \emph{rankable} (respectively, \emph{strictly rankable}). 
For example, the term $(\tY \lambda x.x) \, \underline 0$ is not rankable.

It will be demonstrated later that for any rankable term $M$, if $(M_n)_{n \in \omega}$ is the reduction sequence starting from $M$, then $(f(M_n))_{n\in\omega}$ is a supermartingale, and $M$ terminates almost surely, but first, some preliminaries about supermartingales.
\end{definition}

%\paragraph{}

Fix a probability space $(\Omega, \calF, \mathbb{P})$. 
(In subsequent applications to AST analysis, $\Omega = S$, and $\mathbb{P} = \mu$.)

\begin{definition}\rm
\begin{enumerate}
\item A sequence of random variables $(Y_n)_{n \in \omega}$ adapted to a filtration $(\calF_n)_{n \in \omega}$ is a \emph{supermartingale} if for all $n \in \omega$, $Y_n$ is integrable (i.e.~$\expect{|Y_n|} < \infty$), and $\expect{Y_{n+1} \mid \calF_n} \leq Y_n$ a.s.~\changed[lo]{(i.e.~$\forall A \in \calF_n$, $\int_A \dif \mu \, Y_{n+1} \leq \int_A \dif \mu \,Y_n$).}
\item Let $\epsilon > 0$. A stopping time $T$ and a supermartingale $(Y_n)_{n \in \omega}$, both adapted to filtration $(\calF_n)_{n \in \omega}$, are a \emph{$\epsilon$-ranking supermartingale} if for all $n$, $Y_n \geq 0$ and $\expect{Y_{n+1} \mid \calF_n} \leq Y_n - \epsilon \cdot \mathbf{1}_{\set{T > n}}$.\footnote{For $A \in \calF$, we write ${\bf 1}_A$ for the \emph{indicator function} of $A$, i.e., the random variable defined by ${\bf 1}_A(s) := 1$ if $s \in A$, and $0$ otherwise.}
A \emph{ranking supermartingale} is a $\epsilon$-ranking supermartingale for some $\epsilon > 0$.
\end{enumerate}
\end{definition}

\begin{remark}
\changed[lo]{Our notion of ranking supermartingale is a slight generalisation of the original definition, due to \citep{DBLP:conf/cav/ChakarovS13,DBLP:conf/popl/FioritiH15}, which does not refer to a stopping time explicitly:
Fioriti and Hermanns call a supermartingale $(Y_n)_{n \in \omega}$ \emph{ranking} if $Y_n \geq 0$, and there exists $\epsilon > 0$ such that $\expect{Y_{n+1} \mid \calF_n} \leq Y_n - \epsilon \cdot 1_{\set{Y_n > 0}}$.}
\end{remark}

Intuitively $Y_n$ gives the rank of the program after $n$ steps of computation, and $T$ is the time at which it reaches a value (which may be infinite if it fails to terminate).
In a $\epsilon$-ranking supermartingale, each computation step causes a strict decrease in rank of at least $\epsilon$, provided the term in question is not a value.

\begin{lemma}%[{\citep[Lemma 5.5]{DBLP:conf/popl/FioritiH15}}]
% \citep[Prop 1]{DBLP:conf/popl/ChatterjeeFNH16}}
\label{lem:rank-PAST}
Let $(Y_n)_{n \in \omega}$ be a $\epsilon$-ranking supermartingale with respect to the stopping time $T$, then $T < \infty$ almost surely, and $\expect{T} \leq \frac{\expect{Y_0}}{\epsilon}$.
\end{lemma}

\begin{proof}
We first prove (by induction on $n$): for all $n \in \omega$
\[
%\forall n \in \omega \, . \, 
\expect{Y_n} \leq \expect{Y_0} - \epsilon \cdot \big(\textstyle\sum_{i=0}^{n-1} \mathbb{P}[T > i]\big).
\]
It follows that $\sum_{i=0}^{\infty} \mathbb{P}[T > i]$ converges; hence we have $\lim_{i \to \infty} \mathbb{P}[T > i] = 0$ and so $\mathbb{P}[T < \infty] = 1$.
It then remains to observe: if $T < \infty$ a.s., then $\expect{T} = \sum^\infty_{i=0} \mathbb{P}[T > i]$.
\end{proof}

\begin{remark}
\changed[lo]{\Cref{lem:rank-PAST} is a slight extension of \citep[Lemma 5.5]{DBLP:conf/popl/FioritiH15},
which asserts the same result for the specific stopping time $T : s \mapsto \min\set{n \mid Y_n(s) = 0}$.}
\end{remark}

Let $T$ and $T'$ be stopping times adapted to $(\calF_n)_{n \in \omega}$.
Recall the $\sigma$-algebra (consisting of measurable subsets ``prior to $T$'')
\[
\calF_T := \set{A \in \calF \mid \forall i \in \omega \, . \, A \cap \set{T \leq i} \in \calF_i}
\]
and if $T \leq T'$, then $\calF_{T} \subseteq \calF_{T'}$.

The following is an iterated version of Doob's well-known Optional Sampling Theorem (see, e.g., \cite[\S 6.7]{AshDD00} and \cite[Thm.~7.2]{DBLP:conf/popl/FioritiH15}).
\begin{theorem}[Optional Sampling]
\label{thm:optional sampling}
Let $(X_n)_{n\in \omega}$ be a supermartingale, and $(T_n)_{n \in \omega}$ a sequence of increasing stopping times, both adapted to filtration $(\calF_n)_{n \in \omega}$, then $(X_{T_n})_{n \in \omega}$ is a supermartingale adapted to $(\calF_{T_n})_{n \in \omega}$ if one of the following conditions holds:
\begin{enumerate}
\item each $T_n$ is bounded i.e.~$T_n < c_n$ where $c_n$ is a constant
\item $(X_n)_{n\in \omega}$ is uniformly integrable.
\end{enumerate}
\end{theorem}

\subsection{Ranking functions and supermartingales}

%\emph{Notation.}
\changed[lo]{For the rest of this section, fix the probability space $(S, \calF, \mu)$, and a closed SPCF term $M$.
For $n \in \omega$, define the random variables $M_n(s) := \pi_0 (\red^n(M, s))$, and the filtration $(\mathcal{F}_n)_{n \in \omega}$ where $\mathcal{F}_n := \sigma(M_1, \cdots, M_n)$.}

Our first result is the following theorem.
\begin{theorem}[Rankability] 
\label{thm:rankable and strict rankable}
If a closed SPCF term $M$ is rankable (respectively, strictly rankable) by $f$ satisfying $f(N) = 0$ iff $N$ is a value, then $(f(M_n))_{n \in \omega}$ is a supermartingale (respectively, ranking supermartingale with stopping time $T_M: s \mapsto \min \set{n \mid f(M_n(s)) = 0}$) adapted to the filtration $(\mathcal{F}_n)_{n \in \omega}$. %where $\mathcal{F}_n = \sigma(M_1, \cdots, M_n)$.
\end{theorem}


%\subsection{Proof of \Cref{thm:rankable and strict rankable}.}
We shall obtain the theorem as a corollary of a technical lemma (\Cref{lem:key rankable}).
First, some notation.

Given an $\omega$-sequence (e.g.~$s \in S$) and $m \in \omega$, we write $s_{\leq m} \in I^m$ to mean the prefix of $s$ of length $m$.
%Fix a closed SPCF term $M \in \Lambda^0$, and a ranking function $f$ for it, satisfying $f(N) = 0$ iff $N$ is a value.
%Let $n \in \omega$, define the following random variables on the probability space $(S, \calF, \mu)$:
%\begin{align*}
%M_n(s) &:= \pi_0 (\red^n(M, s))\\
%\ndraw{n}{s} &:= |\{k < n \mid \exists E: M_k(s) = E[\tsample]\}|,
%\end{align*}
For $n \in \omega$, define
\begin{align*}
%M_n(s) &:= \pi_0 (\red^n(M, s))\\
\ndraw{n}{s} &:= |\{k < n \mid \exists E: M_k(s) = E[\tsample]\}|,
\end{align*}
so that $\pi_1 (\red^n(M, s)) = \overbrace{\pi_t( \cdots (\pi_t}^{\ndraw n s}(s))$. 
%and the filtration $\mathcal{F}_n := \sigma(M_1, \cdots, M_n)$.
The $\calF_n$-measurability of $M_n$ (and hence of $\#\mathrm{draw}_n$) follows from \citep{DBLP:conf/icfp/BorgstromLGS16}.
%$\#\mathrm{draw}_n$ is a stopping time (bounded by $n$). 
\iffalse
\akr{$\#\mathrm{draw}_n$ is not a stopping time. It doesn't look like you actually use this claim anyway, so it should just be fine to remove, but did you mean something different?} \lo{I agree, and I don't actually use this claim.}
\fi
Take $s \in A \in \calF_n$ with $\ndraw{n}{s} = l$.
For any $s'\in S$, if $s_{\leq l} = s_{\leq l}'$ then $s' \in A$.
It follows that ${\set{s_{\leq l}} \cdot I^\omega} \subseteq A$.
\lo{NOTE. To fix notation:
\(
\sigma(M_{n}) = \sigma\big(\set{M_{n}^{-1}(\alpha_j, U_{\alpha_j})
\mid \alpha_j\in \mathsf{Sk}_j, U_{\alpha_j} \in \mathcal{B}(\Real^j), j \geq 0}\big)
\)
}
%Take $M \in \Lambda^0$ (closed SPCF terms). Define, for each $n \in \omega$, the random variable $M_n : S \to \Lambda^0$ by $M_n(s) := \pi_0 (\red^n(M, s))$.

\iffalse
\lo{We need to show that each $f(M_n)$ is integrable. LO claimed earlier that $0 \leq f(N) \leq f(M)$ for all $N \in \mathit{Rch}(M)$.
This is of false: take $f$ with $v \, \tsample \mapsto 1$ and $v \, \underline{r} \mapsto 2\, r$ for some value $v$. 
However, it is true that
\[
\int_{S} \mu(\dif s) \, |f(M_n)(s)| 
=
\int_{S} \mu(\dif s) \, f(M_n)(s)
\leq
\int_{S} \mu(\dif s) \, f(M_0)(s)
=
f(M)
\]
the inequality above follows from \Cref{lem:key rankable}.
}
\fi

We say that a given SPCF term is: %\emph{type-1} (respectively 2, 3 and 4) if it has the shape $E[\tY \lambda x. N]$ (respectively $E[\tsample]$, $E[R]$ where $R$ is any other redex, and of a value).
\emph{type 1} if it has the shape $E[\tY \lambda x. N]$, \emph{type 2} if it has the shape $E[\tsample]$; \emph{type 3} if it has the shape $E[R]$ where $R$ is any other redex, and \emph{type 4} if it is a value.
Henceforth fix an $n \geq 0$, and define $\mathbf{T}_i := \set{s \mid M_n(s) \hbox{ is type-$i$}}$.
It is straightforward to see that each $\mathbf{T}_i \in \calF_n$, and $\set{\mathbf{T}_1, \mathbf{T}_2, \mathbf{T}_3, \mathbf{T}_4}$ is a partition of $S$.
%By abuse of language, we refer to the three respective types of redexes as type-$1$, 2 and 3.
Hence it suffices to prove the following lemma.

\iffalse
For $i \in \{1, 2, 3\}$ and $n \in \omega$, define function $f_{i, n+1}(M) : S \to \Real$ by
\[
f_{i, n+1}(M)(s) :=
\begin{cases}
f(M_{n+1}(s)) & \hbox{if }s \in \mathbf{T}_i := 
\set{s \mid M_n(s) \textrm{ is type-$i$}}\\
0 & \textrm{otherwise}
\end{cases}
\]
\begin{lemma}
\label{lem:inde}
For each $i$ and $n$, $f_{i, n+1}(M)$ is %not just $\mathcal{F}_{n+1}$-measurable but also 
$\mathcal{F}_{n}$-measurable.
\end{lemma}

\begin{proof} First fix notation
\begin{align*}
\sigma(M_{n+1}) &= \sigma\big(\set{M_{n+1}^{-1}(U_{\beta_k})
\mid \beta_k\in \mathsf{Sk}_k, U_{\beta_k} \in \mathcal{B}(\Real^k), k \geq 0}\big)\\
\sigma(M_{n}) &= \sigma\big(\set{M_{n}^{-1}(U_{\alpha_j})
\mid \alpha_j\in \mathsf{Sk}_j, U_{\alpha_j} \in \mathcal{B}(\Real^j), j \geq 0}\big);
\end{align*}
and for $\beta_k \in \mathsf{Sk}_i$, we write $\beta_k[\dagger]$ to mean the instantiation of $\beta_k$ by a $k$-vector of numerals $\dagger$; $\alpha_j[\dagger']$ has the same meaning.
Now for each $\beta_k[\dagger] = E[R']$ where $R'$ is the contractum of a type-$i$ redex $R$, there exist $\alpha_j \in \mathsf{Sk}_j$ and $j$-vector $\dagger'$ such that $\alpha_j[\dagger'] = E[R]$ of type $i$.
Moreover, for each $U_{\beta_k}$, there exists $U_{\alpha_j}$ such that $M_{n+1}^{-1}(U_{\beta_k}) = M_{n}^{-1}(U_{\alpha_j}) \in \sigma(M_n)$.
\end{proof}

Plainly
\(
f(M_{n+1}) = %\sum_{i=1}^3 f_{i, n+1}(M).
f_{1, n+1}(M) + f_{2, n+1}(M) + f_{3, n+1}(M),
\)
$\mu$-almost-surely.
%(Unless otherwise stated, all equations and inequations between random variables are assumed to hold only $\mu$-a.s.)
Therefore 
\[
\expect{f(M_{n+1}) \mid \mathcal{F}_n} \nonumber \\
= 
\expect{f_{1, n+1}(M) \mid \mathcal{F}_n} + \expect{f_{2, n+1}(M) \mid \mathcal{F}_n} + \expect{f_{3, n+1}(M) \mid \mathcal{F}_n} 
\]
\begin{align}
& \expect{f(M_{n+1}) \mid \mathcal{F}_n} \nonumber \\
& = \expect{f_{1, n+1}(M) + f_{2, n+1}(M) + f_{3, n+1}(M)  \mid \mathcal{F}_n} 
\nonumber \\
& = \expect{f_{1, n+1}(M) \mid \mathcal{F}_n} + \expect{f_{2, n+1}(M) \mid \mathcal{F}_n} + \expect{f_{3, n+1}(M) \mid \mathcal{F}_n} 
\label{eqn:linear cond ex} 
& = f_{1, n+1}(M) + f_{2, n+1}(M) + f_{3, n+1}(M)
\label{eqn:inde cond exp}
& = f_{1, n+1}(M) + \int_I f() + f_{3, n+1}(M) \label{eqn:inde cond exp} \\
\end{align}
\Cref{eqn:linear cond ex} follows from the linearity of conditional expectation. 
%\Cref{eqn:inde cond exp} is justified because $f_{i, n+1}(M)$ is $\mathcal{F}_n$-measurable (\Cref{lem:inde}).

It remains to show: for all $A \in \calF_n$
\begin{align}
& \int_A \dif \mu \, \expect{f(M_{n+1}) \mid \mathcal{F}_n} \nonumber \\
& \leq  \int_A \mu (\dif s) \, \big(f(M_{n})[s \in \mathbf{T}_1] + f(M_{n})[s \in \mathbf{T}_2] + f(M_{n})[s \in \mathbf{T}_3]\big)
\label{eqn:ts} \\
& = \int_A \dif \mu \, f(M_n). 
\label{eqn:partition} 
\end{align}
where $[s \in \mathbf{T}_i]$ is the Iverson bracket.

Here we use the notation: given function $g : S \to \Real$ and $U \subseteq S$, $g[U] : S \to \Real$ denotes the function
\[
g[U](x) :=
\begin{cases}
g(x) & \textrm{$x \in U$}\\
0 & \textrm{otherwise}
\end{cases}
\]

The inequality (\ref{eqn:ts}) follows immediately from the lemma below; 
and (\ref{eqn:partition}) holds because $\{\mathbf{T}_1, \mathbf{T}_2, \mathbf{T}_3, \mathbf{T}_4\}$ is a partition of $S$.
\fi

\begin{lemma}
\label{lem:key rankable}
For all $i \in \set{1, 2, 3, 4}$ and $A \in \calF_n$
\[
\int_A \mu(\dif s) \, f(M_{n+1})[s \in \mathbf{T}_i] \leq \int_A \mu(\dif s) \, f(M_n)[s \in \mathbf{T}_i]
\; \footnote{where (the Iverson bracket) $[P] := 1$ if the statement $P$ hold, and 0 otherwise.}
\] 
\changed[lo]{Thus 
%$\int_A \mu(\dif s) \, f(M_{n+1}) \leq \int_A \mu(\dif s) \, f(M_n)$, i.e., 
$\mathbb{E}[f(M_{n+1}) \mid \calF_n] \leq f(M_n)$ a.s.}
\end{lemma}

\begin{proof}
We show the non-trivial case of $i = 2$.
First we express 
\begin{equation}
f(M_{n+1})[s \in \mathbf{T}_2] = \sum_{i \in \calI} 
f(E_i[\underline{\sigma_i(s)}][\underline{\rho(s)}])[s \in U_i]
\label{eqn:f 2 n+1}
\end{equation}
where 
\begin{itemize}
\item $\calI$ is a countable indexing set
\item $E_i[\cdot][\tsample] \in \mathsf{Sk}_{j_i}$, and $\sigma_i : S \to \Real^{j_i}$, and $\rho(s) := \pi_h(\pi_1(\red^n(M, s))) = \pi_h(\pi_t^{l_i}(s)) \in \Real$ 
\item $\set{U_i}_{i \in \calI}$ is a partition of $\mathbf{T}_2$, 
where each $U_i$ is determined by a skeletal term $E_i[\cdot][\tsample]$ and a number (of draws) $l_i \leq n$, satisfying
\(
s \in U_i
\iff
(E_i[\underline{r}][{\tsample}], \pi_t^{l_i}(s)) = \red^n(M, s),
\;
\hbox{for some }r \in \Real^{j_i}.
\)
(We use the (measurable) function $\sigma_i : S \to \Real^{j_i}$ to skolemise the existentially quantified $r$.)
Equivalently
\[
U_i := \#\mathrm{draw}_n^{-1}(l_i) \cap M_n^{-1}(E_i[\cdot][\tsample], \Real^{j_i}) \in \calF_n.
\]
%\lo{I.e.~$(E_i[\underline{\sigma_i(s)}][{\tsample}], \pi_t^{l_i}(s)) = \red^n(M, s)$ iff $s \in U_i$.}
\end{itemize}

Observe that if $s \in U_i$ then $\set{s_{\leq l_i}} \cdot I^\omega \subseteq U_i$;
in fact $(U_i)_{\leq l_i} \cdot I^\omega = U_i$.
%Moreover, for any $A \in \calF_n$, if $s \in A$ then $\set{s_{\leq l}} \cdot I^\omega \subseteq A$.
This means that for any measurable $g : S \to \Real_{\geq 0}$, if $g(s)$ only depends on the prefix of $s$ of length $(l_i+1)$, then, writing $\widehat{g} : I^{l_i+1} \to \Real_{\geq 0}$ where $g(s) = \widehat{g}(s_{\leq l_i+1})$, we have: for any $A \in \calF_n$ 
\begin{equation}
\int_{A \cap U_i}  \mu(\dif s) \, g(s) = 
\int_{(A \cap U_i)_{\leq l_i+1}} \Leb_{l_i+1}(\dif t) \, \widehat{g}(t)
\label{eqn:truncate}
\end{equation}
%(For simplicity, we will write $g' = g$ in the following.)
%where $A_{\leq m} := \set{s_{\leq m} \mid s \in A}$. 

Take $s \in U_i$, and set $l = l_i$.
Plainly $\sigma_i(s)$ depends on $s_{\leq l}$, and $\rho(s)$ depends on $s_{\leq l +1}$.
Take $u \in (U_i)_{\leq l}$.
It then follows from the definition of ranking function that
\[%\textstyle
\int_I \Leb(\dif r) \, f(E_i[\underline{\widehat{\sigma_i}(u)}][\underline{r}])) \leq f(E_i[\underline{\widehat{\sigma_i}(u)}][\tsample])).
\]
Take $A \in \calF_n$, and integrating both sides, we get
\begin{align*}
& \int_{(A \cap U_i)_{\leq l}} \Leb_l(\dif u) \, \int_I \textrm{Leb}(\dif r) \, f(E_i[\underline{\widehat{\sigma_i}(u)}][\underline{r}])) \\
& \leq \int_{(A \cap U_i)_{\leq l}} \Leb_l(\dif u) \, f(E_i[\underline{\widehat{\sigma_i}(u)}][\tsample])).
\end{align*}
Since $\Leb_{l+1}$ is the (unique) product measure satisfying $\Leb_{l+1}(V \times B) = \Leb_l(V) \cdot \Leb(B)$, and $(U_i)_{\leq l_i} \cdot I^\omega = U_i$, we have
%it follows from the preceding observation that
\begin{align*}
& \int_{(A \cap U_i)_{\leq l+1}} \Leb_{l+1}(\dif u') \, f(E_i[\underline{\widehat{\sigma_i}(u')}][\underline{\widehat{\rho}(u')}])) \\
& \leq 
\int_{(A \cap U_i)_{\leq l+1}} \Leb_{l+1}(\dif u') \, f(E_i[\underline{\widehat{\sigma_i}(u')}][\tsample]))
\end{align*}
and so, by (\ref{eqn:truncate})
\begin{align}
& \int_{A \cap U_i} \mu(\dif s) \, f(E_i[\underline{\sigma_i(s)}][\underline{\rho(s)}])) \nonumber \\
& \leq 
\int_{A \cap U_i} \mu(\dif s) \, f(E_i[\underline{\sigma_i(s)}][\tsample])).
\label{eqn:a u ui}
\end{align}

Now, integrating both sides of (\ref{eqn:f 2 n+1}), we have
\begin{align*}
& \int_A \mu(\dif s) \, f_{n+1}(M)[s \in \mathbf{T}_i] \\
&= 
\int_A \mu(\dif s) \, \sum_{i \in \calI} f(E_i[\underline{\sigma_i(s)}][\underline{\rho(s)}])[s \in U_i] \\
&= 
\sum_{i \in \calI} \int_{A \cap U_i} \mu(\dif s) \, f(E_i[\underline{\sigma_i(s)}][\underline{\rho(s)}])\\
&\leq 
\sum_{i \in \calI} \int_{A \cap U_i} \mu(\dif s) \, f(E_i[\underline{\sigma_i(s)}][\tsample])
\quad \hbox{$\because$ (\ref{eqn:a u ui})}\\
&= 
\int_{A} \mu(\dif s) \, \sum_{i \in \calI} \, f(E_i[\underline{\sigma_i(s)}][\tsample])[s \in U_i]\\
&= \int_{A} \mu(\dif s) f_{n}(M)[s \in \mathbf{T}_2]
%\quad \hbox{$\because$ (\ref{eqn:f 2 n+1})}
\end{align*}

\end{proof}

As an immediate corollary of \Cref{lem:key rankable}, each $f(M_n)$ is integrable:
\begin{align*}
\int_{S} \mu(\dif s) \, |f(M_n)(s)| 
&=
\int_{S} \mu(\dif s) \, f(M_n)(s)
\\
&\leq
\int_{S} \mu(\dif s) \, f(M_0)(s)
=
f(M).
\end{align*}

\iffalse
[** To see $f_{2, n+1}(M) \leq f(M_n)[T_2]$, take $s \in T_2$. Then $f_{2, n+1}(M)(s) = f(E[\underline{a}])$ and $M_n = E[\tsample]$, for some $a \in [0, 1]$ and evaluation context $E$. Hence 
\[
f_{2, n+1}(M)(s) \leq \int_I f(E[\underline{r}]) \, \mu_{leb}(\textrm{d} r)
\leq f(E[\tsample]) = f(M_n)[T_2](s).
\]
**]
\fi
This concludes the proof of %\Cref{thm:rankable gives supermartingale}. 
\Cref{thm:rankable and strict rankable}. %\hfill \qed

\subsection{Soundness of rankability}

In the rest of this section we show that if $M \in \Lambda^0$ is rankable by $f$, then $M$ is AST.

Let $f$ be a ranking function on $M$ satisfying $f(N) = 0$ iff $N$ is a value.
Define random variables on the probability space $(S, \calF, \mu)$:
\begin{align}
T_{-1}(s) & := -1 \nonumber \\
T_{n+1}(s) & := \min \{ k \mid k>T_n(s), M_k(s) \textrm{ a value} \nonumber\\
& \qquad\qquad\qquad\qquad\qquad \hbox{or of form } E[\tY \lambda x. N] \} \nonumber \\
X_n(s) & := f(M_n(s)) \nonumber \\
Y_n(s) & := X_{T_n}(s) \nonumber \\
T_M^\tY(s) &:= \min \set{n \mid M_{T_n(s)}(s) \textrm{ is a value}} \label{eq:y stopping time} 
%T_M(s) & := \min \set{n \mid X_n(s) = 0} \nonumber
\end{align}

%The random variable $T_0(s)$ is the least $k \geq 0$ such that $M_k(s)$ is either a value or a $\tY$-redex.

%$T_1(s)$ is the least $k \geq 0$ such that $M_k(s)$ is either a value or the second occurrence of a $\tY$-redex.

%Thus the random variable $T_n(s)$ is the least $k \geq 0$ such that $M_k(s)$ is either a value or the $(n+1)$-occurrence of a $\tY$-redex (in the reduction sequence $M_0(s), M_1(s), \ldots$).
%Notice that each $T_n$ is a stopping time w.r.t.~filtration $(\calF_n)_{n \in \omega}$.
We first state a useful property about r.v.~$T_0, T_1, T_2, \cdots$.
\begin{restatable}{lemma}{TnBounded}
\label{lem:TnBounded}
$(T_n)_{n \in\omega}$ is an increasing sequence of stopping times adapted to $(\calF_n)_{n \in \omega}$, and each $T_i$ is bounded.
\end{restatable}

%The random variable $T_M$ is a stopping time w.r.t.~filtration $(\calF_n)_{n \in \omega}$. 
%Since $f(M_n(s)) = 0$ iff $M_n(s)$ is a value, $T_M$ is the \emph{runtime of $M$}.

The random variable $T_M^\tY$, which we call the \emph{$\tY$-runtime of $M$}, can equivalently be defined as the number of $\tY$-reduction steps in the reduction sequence of $M$. 
Note that, as the type system ensures that the reduction relation excluding $\tY$-reduction is strongly normalising, only finitely many reductions can occur in a row without one of them being a $\tY$-reduction, therefore $T_M^\tY < \infty$ a.s.~iff $M$ is AST. 
Moreover 
\begin{restatable}{lemma}{TMtYStoppingTime}
\label{lem:TMtY is a stopping time}
$T_M^\tY$ is a stopping time adapted to $(\calF_{T_n})_{n \in \omega}$.
\end{restatable}

\begin{theorem}[Soundness of rankability] \label{thm:rankable implies termination}
\begin{enumerate}
\item If a closed SPCF term $M$ is rankable, then $M$ is AST (equivalently, $T^{\tY}_M < \infty$ almost surely), and $M$ is $\tY$-positively almost-sure terminating ($\tY$-PAST) i.e.~$\expect{T^{\tY}_M} < \infty$. 

\item If a closed SPCF term $M$ is strictly rankable, then $\expect{T_M} < \infty$ i.e.~$M$ is positively almost-sure terminating (PAST).
\end{enumerate}
\end{theorem}

\begin{proof}
Let $f$ be a ranking function on $M$.
For 1, since $(T_n)_{n \in\omega}$ is an increasing sequence of stopping times, each is bounded and adapted to $(\calF_n)_{n \in \omega}$ (\Cref{lem:TnBounded}),
and $(f(M_n))_{n \in \omega}$ is a supermartingale also adapted to $(\calF_n)_{n \in \omega}$ (\Cref{thm:rankable and strict rankable}),
it follows from the Optional Sampling \Cref{thm:optional sampling} that $(Y_n)_{n \in \omega}$ where $Y_n := f(M_{T_n})$ is a supermartingale adapted to the filtration $(\calF_{T_n})_{n \in \omega}$.
Notice the stopping time $T_M^\tY$ is also adapted to $(\calF_{T_n})_{n \in \omega}$ (\Cref{lem:TMtY is a stopping time}); and we have that $(Y_n)_{n \in \omega}$ is a $1$-ranking supermartingale.
Therefore, by \Cref{lem:rank-PAST}, $T^{\tY}_M < \infty$ a.s.~and $\expect{T^{\tY}_M} < \infty$.

%For 2, we have that $(f(M_n))_{n \in \omega}$ is a ranking supermartingale (\Cref{thm:rankable and strict rankable}) w.r.t.~stopping time $T_M$. 
%It follows immediately from \Cref{lem:rank-PAST} that $\expect{T_M} < \infty$.
Statement 2 follows immediately from \Cref{thm:rankable and strict rankable} and \Cref{lem:rank-PAST}.
\end{proof}

Thus the method of (strict) ranking function is sound for proving (positive) a.s.~termination of SPCF programs.
It is in fact also complete in a sense: if $\expect{T^\tY_N} < \infty$ for all $N \in \mathit{Rch}(M)$ then $M$ is rankable (\Cref{thm:minimal}).
