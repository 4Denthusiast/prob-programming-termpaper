% !TEX root = main.tex
\section{Supermartingales}
\label{sec:supermartingales}

One approach to proving that a term terminates almost surely is to find some variant that is bounded below and, on average, decreases sufficiently quickly that it must eventually reach 0, similarly to the approach taken by 
%\citep{DBLP:journals/pacmpl/McIverMKK18} 
\cite{DBLP:conf/popl/FioritiH15} and others for imperative programs.

These variants are defined as functions from reachable terms (i.e.~possible states of the program's execution) to real numbers. Specifically, let the set of reachable terms from a given closed starting term $M$ be $Rch(M) := \{N \in \Lambda \mid M \to^* N \}$, with the $\sigma$-algebra induced as a subset of $\Lambda$.

\begin{definition}\rm
\label{def:ranking function}
A \emph{ranking function on $M \in \Lambda^0$} is a measurable function $f:\mathit{Rch}(M) \to \mathbb{R}$ such that $f(N) \geq 0$ for all $N$\footnote{The fact that the ranking function can be 0 in some cases before it reaches a value is necessary to get \Cref{thm:minimal} to work neatly.}, and
\begin{enumerate}
    \item $f(E[\tY \lambda x. N]) \geq 1+ f(E[\lambda z. N[(\tY \lambda x. N)/x] z)$ where $z$ is not free in $N$
    \item $f(E[\tsample]) \geq \int_I f(E[\underline{x}]) \, \Leb(\mathrm{d}x)$
    \item $f(E[R]) \geq f(E[R'])$ for any other redex $R$, where $R \to R'$.
\end{enumerate}
\iffalse
\lo{@Andrew: As defined, ranking function $f$ is not required to satisfy: $f(N) = 0$ iff $N$ is a value. But for AST analysis, we always require $f$ to satisfy this property. It seems cleaner to include this in the definition.} 
\akr{The fact that the ranking function can be 0 in some cases before it reaches a value is necessary to get \Cref{thm:minimal} to work neatly.}
\lo{OK. Let's leave \Cref{def:ranking function} as it is.}
\fi
We say that the ranking function $f$ is \emph{strict} if there exists $\epsilon > 0$ such that for all $E$ and $R \to R'$, $f(E[R']) \leq f(E[R]) - \epsilon$.

Any closed term for which a ranking (respectively, strict ranking) function exists is called \emph{rankable} (respectively, \emph{strictly rankable}). 
For example, the term $(\tY \lambda x.x) \, \underline 0$ is not rankable.
\end{definition}

It will be demonstrated later that for any rankable term $M$, if $(M_n)_{n \geq 0}$ is the reduction sequence starting from $M$, then $(f(M_n))_{n \geq 0}$ is a supermartingale, and $M$ terminates almost surely, but first, some preliminaries about supermartingales.
\lo{It is confusing (strictly speaking, incorrect) to say that $(M_n)_{n \geq 0}$ is a reduction sequence from $M$. Formally $M_n$ is the random variable $M_n: s \mapsto \pi_0 (\red^n(M, s))$.}
\akr{I guess it's implicitly identifying a sequence of functions ($(M_n)_{n \geq 0}$), and a function producing sequences (a reduction-sequence-valued random variable), but this sort of thing seems very standard in dealing with random variables (e.g.~applying a function to some random variables, which is really a sort of concatenation).}

%\paragraph{}

Fix a probability space $(\Omega, \calF, \mathbb{P})$ and a filtration $(\calF_n)_{n \geq 0}$. 
(In subsequent applications to termination analysis, $\Omega = \entrosp$, and $\mathbb{P} = \mu_{\entrosp}$.)
Let $T$ be a random variable that takes values in $\mathbb{N} \cup \set{\infty}$.
We call $T$ a \emph{stopping time adapted to $(\calF_n)_{n \geq 0}$} just if $\set{T = n} \in \calF_n$, for all $n \geq 0$.

\begin{definition}\rm
\begin{enumerate}
\item A sequence of random variables $(Y_n)_{n \geq 0}$ adapted to a filtration $(\calF_n)_{n \geq 0}$ is a \emph{supermartingale} if for all $n \geq 0$, $Y_n$ is integrable (i.e.~$\expect{|Y_n|} < \infty$), and $\expect{Y_{n+1} \mid \calF_n} \leq Y_n$ a.s.~(i.e.~for all $A \in \calF_n$, $\int_A \mathbb{P}(\dif \omega) \, Y_{n+1}(\omega) \leq \int_A \mathbb{P}(\dif \omega) \,Y_n(\omega)$).
\item Let $\epsilon > 0$. 
Given a stopping time $T$ and a supermartingale $(Y_n)_{n \geq 0}$, both adapted to filtration $(\calF_n)_{n \geq 0}$, 
we say that $(Y_n)_{n \geq 0}$ is a \emph{$\epsilon$-ranking supermartingale w.r.t.~$T$} if for all $n$, $Y_n \geq 0$ and $\expect{Y_{n+1} \mid \calF_n} \leq Y_n - \epsilon \cdot \mathbf{1}_{\set{T > n}}$.
\footnote{For $A \in \calF$, we write ${\bf 1}_A$ for the \emph{indicator function} of $A$, i.e., the random variable defined by ${\bf 1}_A(\omega) := 1$ if $\omega \in A$, and $0$ otherwise.} %\lo{\LaTeX\ does not allow the preceding bracketed sentence to be typeset as a footnote. Strange!}\lo{Now it does. Stranger.}
A \emph{ranking supermartingale} w.r.t.~$T$ is a $\epsilon$-ranking supermartingale w.r.t.~$T$ for some $\epsilon > 0$.
\end{enumerate}
\end{definition}

\begin{remark}
Our notion of ranking supermartingale is a slight generalisation of the original definition, due to \citep{DBLP:conf/cav/ChakarovS13,DBLP:conf/popl/FioritiH15}, which does not refer to a stopping time explicitly:
Fioriti and Hermanns call a supermartingale $(Y_n)_{n \geq 0}$ \emph{ranking} if $Y_n \geq 0$, and there exists $\epsilon > 0$ such that $\expect{Y_{n+1} \mid \calF_n} \leq Y_n - \epsilon \cdot {\bf 1}_{\set{Y_n > 0}}$.
\end{remark}

Intuitively $Y_n$ gives the rank of the program after $n$ steps of computation, and $T$ is the time at which it reaches a value (which may be infinite if it fails to terminate).
In a $\epsilon$-ranking supermartingale, each computation step causes a strict decrease in rank of at least $\epsilon$, provided the term in question is not a value.

\begin{restatable}{lemma}{rankPast}
%\begin{lemma}%[{\citep[Lemma 5.5]{DBLP:conf/popl/FioritiH15}}]
% \citep[Prop 1]{DBLP:conf/popl/ChatterjeeFNH16}}
\label{lem:rank-PAST}
Let $(Y_n)_{n \geq 0}$ be a $\epsilon$-ranking supermartingale w.r.t.~the stopping time $T$, then $T < \infty$ a.s., and $\expect{T} \leq \frac{\expect{Y_0}}{\epsilon}$.
%\end{lemma}
\end{restatable}

\begin{remark}
\changed[lo]{\Cref{lem:rank-PAST} is a slight extension of \citep[Lemma 5.5]{DBLP:conf/popl/FioritiH15},
which asserts the same result but for the specific stopping time $T : \omega \mapsto \min\set{n \mid Y_n(\omega) = 0}$.}
\end{remark}

Let $T$ and $T'$ be stopping times adapted to $(\calF_n)_{n \geq 0}$.
Recall the $\sigma$-algebra (consisting of measurable subsets ``prior to $T$'')
\[
\calF_T := \set{A \in \calF \mid \forall i \geq 0 \, . \, A \cap \set{T \leq i} \in \calF_i}
\]
and if $T \leq T'$, then $\calF_{T} \subseteq \calF_{T'}$.

The following is an iterated version of Doob's well-known Optional Sampling Theorem (see, e.g., \cite[\S 6.7]{AshDD00} and \cite[Thm.~7.2]{DBLP:conf/popl/FioritiH15}).
\begin{theorem}[Optional Sampling]
\label{thm:optional sampling}
Let $(X_n)_{n \geq 0}$ be a supermartingale, and $(T_n)_{n \geq 0}$ a sequence of increasing stopping times, all adapted to filtration $(\calF_n)_{n \geq 0}$, then $(X_{T_n})_{n \geq 0}$ is a supermartingale adapted to $(\calF_{T_n})_{n \geq 0}$ if one of the following conditions holds:
\begin{enumerate}
\item each $T_n$ is bounded i.e.~$T_n < c_n$ where $c_n$ is a constant
\item $(X_n)_{n \geq 0}$ is uniformly integrable.
\end{enumerate}
\end{theorem}

\subsection{Ranking functions and supermartingales}

Henceforth, fix the probability space $(\entrosp, \Sigma_\entrosp, \mu_{\entrosp})$, and a closed PPCF term $M$.
For $n \geq 0$, define the random variables 
\begin{align*}
M_n(s) &:= \pi_0 (\red^n(M, s))\\
T_M(s) &:= \min \set{n \mid \hbox{$M_n(s)$ is a value}}
\end{align*} 
and the filtration $(\mathcal{F}_n)_{n \geq 0}$ where $\mathcal{F}_n := \sigma(M_1, \cdots, M_n)$.
Thus $T_M$ is the \emph{runtime} of $M$ (and $M$ is AST iff $\mu_{\entrosp}(T_M < \infty) = 1$).

Our first result is the following theorem.
\begin{theorem}[Rankability] 
\label{thm:rankable and strict rankable}
If a closed PPCF term $M$ is rankable (respectively, strictly rankable) by $f$ 
then $(f(M_n))_{n \geq 0}$ is a supermartingale (respectively, ranking supermartingale w.r.t.~stopping time $T_M$) adapted to $(\mathcal{F}_n)_{n \geq 0}$. %where $\mathcal{F}_n = \sigma(M_1, \cdots, M_n)$.
\end{theorem}
\lo{@Andrew: A better name for this theorem: ``Ranking function'', ``Supermartingale'', ``(Ranking) supermartingale''?}

%\subsection{Proof of \Cref{thm:rankable and strict rankable}.}
We shall obtain the theorem as a corollary of a technical lemma (\Cref{lem:key rankable}).

\iffalse
\lo{We need to show that each $f(M_n)$ is integrable. LO claimed earlier that $0 \leq f(N) \leq f(M)$ for all $N \in \mathit{Rch}(M)$.
This is of false: take $f$ with $v \, \tsample \mapsto 1$ and $v \, \underline{r} \mapsto 2\, r$ for some value $v$. 
However, it is true that
\[
\int_{S} \mu(\dif s) \, |f(M_n)(s)| 
=
\int_{S} \mu(\dif s) \, f(M_n)(s)
\leq
\int_{S} \mu(\dif s) \, f(M_0)(s)
=
f(M)
\]
the inequality above follows from \Cref{lem:key rankable}.
}
\fi

We say that a given PPCF term is: %\emph{type-1} (respectively 2, 3 and 4) if it has the shape $E[\tY \lambda x. N]$ (respectively $E[\tsample]$, $E[R]$ where $R$ is any other redex, and of a value).
\emph{type 1} if it has the shape $E[\tY \lambda x. N]$, \emph{type 2} if it has the shape $E[\tsample]$; \emph{type 3} if it has the shape $E[R]$ where $R$ is any other redex, and \emph{type 4} if it is a value.
Henceforth fix an $n \geq 0$, and define $\mathbf{T}_i := \set{s \mid M_n(s) \hbox{ is type $i$}}$.
It is straightforward to see that each $\mathbf{T}_i \in \calF_n$, and $\set{\mathbf{T}_1, \mathbf{T}_2, \mathbf{T}_3, \mathbf{T}_4}$ is a partition of $\entrosp$.
%By abuse of language, we refer to the three respective types of redexes as type-$1$, 2 and 3.
Hence it suffices to prove the following lemma.

\iffalse
For $i \in \{1, 2, 3\}$ and $n \geq 0$, define function $f_{i, n+1}(M) : \entrosp \to \Real$ by
\[
f_{i, n+1}(M)(s) :=
\begin{cases}
f(M_{n+1}(s)) & \hbox{if }s \in \mathbf{T}_i := 
\set{s \mid M_n(s) \textrm{ is type-$i$}}\\
0 & \textrm{otherwise}
\end{cases}
\]
\begin{lemma}
\label{lem:inde}
For each $i$ and $n$, $f_{i, n+1}(M)$ is %not just $\mathcal{F}_{n+1}$-measurable but also 
$\mathcal{F}_{n}$-measurable.
\end{lemma}

\begin{proof} First fix notation
\begin{align*}
\sigma(M_{n+1}) &= \sigma\big(\set{M_{n+1}^{-1}(U_{\beta_k})
\mid \beta_k\in \mathsf{Sk}_k, U_{\beta_k} \in \mathcal{B}(\Real^k), k \geq 0}\big)\\
\sigma(M_{n}) &= \sigma\big(\set{M_{n}^{-1}(U_{\alpha_j})
\mid \alpha_j\in \mathsf{Sk}_j, U_{\alpha_j} \in \mathcal{B}(\Real^j), j \geq 0}\big);
\end{align*}
and for $\beta_k \in \mathsf{Sk}_i$, we write $\beta_k[\dagger]$ to mean the instantiation of $\beta_k$ by a $k$-vector of numerals $\dagger$; $\alpha_j[\dagger']$ has the same meaning.
Now for each $\beta_k[\dagger] = E[R']$ where $R'$ is the contractum of a type-$i$ redex $R$, there exist $\alpha_j \in \mathsf{Sk}_j$ and $j$-vector $\dagger'$ such that $\alpha_j[\dagger'] = E[R]$ of type $i$.
Moreover, for each $U_{\beta_k}$, there exists $U_{\alpha_j}$ such that $M_{n+1}^{-1}(U_{\beta_k}) = M_{n}^{-1}(U_{\alpha_j}) \in \sigma(M_n)$.
\end{proof}

Plainly
\(
f(M_{n+1}) = %\sum_{i=1}^3 f_{i, n+1}(M).
f_{1, n+1}(M) + f_{2, n+1}(M) + f_{3, n+1}(M),
\)
$\mu$-almost surely.
%(Unless otherwise stated, all equations and inequations between random variables are assumed to hold only $\mu$-a.s.)
Therefore 
\[
\expect{f(M_{n+1}) \mid \mathcal{F}_n} \nonumber \\
= 
\expect{f_{1, n+1}(M) \mid \mathcal{F}_n} + \expect{f_{2, n+1}(M) \mid \mathcal{F}_n} + \expect{f_{3, n+1}(M) \mid \mathcal{F}_n} 
\]
\begin{align}
& \expect{f(M_{n+1}) \mid \mathcal{F}_n} \nonumber \\
& = \expect{f_{1, n+1}(M) + f_{2, n+1}(M) + f_{3, n+1}(M)  \mid \mathcal{F}_n} 
\nonumber \\
& = \expect{f_{1, n+1}(M) \mid \mathcal{F}_n} + \expect{f_{2, n+1}(M) \mid \mathcal{F}_n} + \expect{f_{3, n+1}(M) \mid \mathcal{F}_n} 
\label{eqn:linear cond ex} 
& = f_{1, n+1}(M) + f_{2, n+1}(M) + f_{3, n+1}(M)
\label{eqn:inde cond exp}
& = f_{1, n+1}(M) + \int_I f() + f_{3, n+1}(M) \label{eqn:inde cond exp} \\
\end{align}
\Cref{eqn:linear cond ex} follows from the linearity of conditional expectation. 
%\Cref{eqn:inde cond exp} is justified because $f_{i, n+1}(M)$ is $\mathcal{F}_n$-measurable (\Cref{lem:inde}).

It remains to show: for all $A \in \calF_n$
\begin{align}
& \int_A \dif \mu \, \expect{f(M_{n+1}) \mid \mathcal{F}_n} \nonumber \\
& \leq  \int_A \mu (\dif s) \, \big(f(M_{n})[s \in \mathbf{T}_1] + f(M_{n})[s \in \mathbf{T}_2] + f(M_{n})[s \in \mathbf{T}_3]\big)
\label{eqn:ts} \\
& = \int_A \dif \mu \, f(M_n). 
\label{eqn:partition} 
\end{align}
where $[s \in \mathbf{T}_i]$ is the Iverson bracket.

Here we use the notation: given function $g : \entrosp \to \Real$ and $U \subseteq \entrosp$, $g[U] : \entrosp \to \Real$ denotes the function
\[
g[U](x) :=
\begin{cases}
g(x) & \textrm{$x \in U$}\\
0 & \textrm{otherwise}
\end{cases}
\]

The inequality (\ref{eqn:ts}) follows immediately from the lemma below; 
and (\ref{eqn:partition}) holds because $\{\mathbf{T}_1, \mathbf{T}_2, \mathbf{T}_3, \mathbf{T}_4\}$ is a partition of $\entrosp$.
\fi

\begin{restatable}[Technical]{lemma}{TechnicalRankingSupermartingale}
\label{lem:key rankable}
For all $i \in \set{1, 2, 3, 4}$ and $A \in \calF_n$
\[
\int_A \mu_{\entrosp}(\dif s) \, f(M_{n+1})[s \in \mathbf{T}_i] \leq \int_A \mu_{\entrosp}(\dif s) \, f(M_n)[s \in \mathbf{T}_i]
\; \footnote{where (the Iverson bracket) $[P] := 1$ if the statement $P$ hold, and 0 otherwise.}
\] 
%$\int_A \mu_{\entrosp}(\dif s) \, f(M_{n+1}) \leq \int_A \mu_{\entrosp}(\dif s) \, f(M_n)$, i.e., 
Hence $\mathbb{E}[f(M_{n+1}) \mid \calF_n] \leq f(M_n)$ a.s.
\end{restatable}
As an immediate corollary of \Cref{lem:key rankable}, each $f(M_n)$ is integrable
\iffalse
\begin{align*}
\int_{\entrosp} \mu_{\entrosp}(\dif s) \, |f(M_n)(s)| 
&=
\int_{\entrosp} \mu_{\entrosp}(\dif s) \, f(M_n)(s)
\\
&\leq
\int_{\entrosp} \mu_{\entrosp}(\dif s) \, f(M_0)(s)
=
f(M).
\end{align*}

[** To see $f_{2, n+1}(M) \leq f(M_n)[T_2]$, take $s \in T_2$. Then $f_{2, n+1}(M)(s) = f(E[\underline{a}])$ and $M_n = E[\tsample]$, for some $a \in [0, 1]$ and evaluation context $E$. Hence 
\[
f_{2, n+1}(M)(s) \leq \int_I f(E[\underline{r}]) \, \mu_{leb}(\textrm{d} r)
\leq f(E[\tsample]) = f(M_n)[T_2](s).
\]
**]
\fi
This concludes the proof of \Cref{thm:rankable and strict rankable}. 

\subsection{Soundness of rankability}

In the rest of this section we show that if $M \in \Lambda^0$ is rankable, then $M$ is AST: in other words, the method of ranking function is sound for proving a.s.~termination of PPCF programs.

Let $f$ be a ranking function on $M$.
Define random variables on the probability space $(\entrosp, \Sigma_\entrosp, \mu_{\entrosp})$:
\begin{align}
T_{-1}(s) & := -1 \nonumber \\
T_{n+1}(s) & := \min \{ k \mid k>T_n(s), M_k(s) \textrm{ a value} \nonumber\\
& \qquad\qquad\qquad\qquad\qquad \hbox{or of form } E[\tY \lambda x. N] \} \nonumber \\
X_n(s) & := f(M_n(s)) \nonumber \\
Y_n(s) & := X_{T_n}(s) \nonumber \\
T_M^\tY(s) &:= \min \set{n \mid M_{T_n(s)}(s) \textrm{ is a value}} \label{eq:y stopping time} 
%T_M(s) & := \min \set{n \mid X_n(s) = 0} \nonumber
\end{align}

%The random variable $T_0(s)$ is the least $k \geq 0$ such that $M_k(s)$ is either a value or a $\tY$-redex.

%$T_1(s)$ is the least $k \geq 0$ such that $M_k(s)$ is either a value or the second occurrence of a $\tY$-redex.

%Thus the random variable $T_n(s)$ is the least $k \geq 0$ such that $M_k(s)$ is either a value or the $(n+1)$-occurrence of a $\tY$-redex (in the reduction sequence $M_0(s), M_1(s), \ldots$).
%Notice that each $T_n$ is a stopping time w.r.t.~filtration $(\calF_n)_{n \geq 0}$.
We first state a useful property about r.v.~$T_0, T_1, T_2, \cdots$.
\begin{restatable}{lemma}{TnBounded}
\label{lem:TnBounded}
$(T_n)_{n \geq 0}$ is an increasing sequence of stopping times adapted to $(\calF_n)_{n \geq 0}$, and each $T_i$ is bounded.
\end{restatable}

%The random variable $T_M$ is a stopping time w.r.t.~filtration $(\calF_n)_{n \geq 0}$. 
%Since $f(M_n(s)) = 0$ iff $M_n(s)$ is a value, $T_M$ is the \emph{runtime of $M$}.

The random variable $T_M^\tY$, which we call the \emph{$\tY$-runtime of $M$}, can equivalently be defined as the number of $\tY$-reduction steps in the reduction sequence of $M$. 
Note that, as the type system ensures that the reduction relation excluding $\tY$-reduction is strongly normalising, only finitely many reductions can occur in a row without one of them being a $\tY$-reduction, therefore $T_M^\tY < \infty$ a.s.~iff $M$ is AST. 
Moreover 
\begin{restatable}{lemma}{TMtYStoppingTime}
\label{lem:TMtY is a stopping time}
$T_M^\tY$ is a stopping time adapted to $(\calF_{T_n})_{n \geq 0}$.
\end{restatable}

\begin{theorem}[Soundness of rankability] \label{thm:rankable implies termination}
\begin{enumerate}
\item If a closed PPCF term $M$ is rankable, then $M$ is AST (equivalently, $T^{\tY}_M < \infty$ almost surely), and $M$ is $\tY$-positively almost sure terminating ($\tY$-PAST) i.e.~$\expect{T^{\tY}_M} < \infty$. 

\item If a closed PPCF term $M$ is strictly rankable, then $\expect{T_M} < \infty$ i.e.~$M$ is positively almost sure terminating (PAST).
\end{enumerate}
\end{theorem}

\begin{proof}
Let $f$ be a ranking function on $M$.
For 1, since $(T_n)_{n \geq 0}$ is an increasing sequence of stopping times, each is adapted to $(\calF_n)_{n \geq 0}$ and bounded (\Cref{lem:TnBounded}),
and $(f(M_n))_{n \geq 0}$ is a supermartingale also adapted to $(\calF_n)_{n \geq 0}$ (\Cref{thm:rankable and strict rankable}),
it follows from the Optional Sampling \Cref{thm:optional sampling} that $(Y_n)_{n \geq 0}$ %where $Y_n := f(M_{T_n})$ 
is a supermartingale adapted to $(\calF_{T_n})_{n \geq 0}$.
Notice the stopping time $T_M^\tY$ is also adapted to $(\calF_{T_n})_{n \geq 0}$ (\Cref{lem:TMtY is a stopping time}); and we have that $(Y_n)_{n \geq 0}$ is a $1$-ranking supermartingale.
Therefore, by \Cref{lem:rank-PAST}, $T^{\tY}_M < \infty$ a.s.~and $\expect{T^{\tY}_M} < \infty$.

%For 2, we have that $(f(M_n))_{n \geq 0}$ is a ranking supermartingale (\Cref{thm:rankable and strict rankable}) w.r.t.~stopping time $T_M$. 
%It follows immediately from \Cref{lem:rank-PAST} that $\expect{T_M} < \infty$.
Statement 2 follows at once from \Cref{thm:rankable and strict rankable} and \Cref{lem:rank-PAST}.
\end{proof}

Thus the method of (strict) ranking function is sound for proving (positive) a.s.~termination of PPCF programs.
It is in fact also complete in a sense: if $\expect{T^\tY_N} < \infty$ for all $N \in \mathit{Rch}(M)$ then $M$ is rankable (\Cref{thm:minimal}).
