% !TEX root = main.tex
\section{Antitone ranking functions}
\label{sec:antitone}

\begin{example}[Random walk]
\label{ex:ac-ranking}
\begin{compactenum}[(i)]
\item One-dimensional (1D) biased (towards 0) random walk
\[
M_1 = 
\big(\tY \, \lambda f n . \, 
\tif{n = 0}{0}{f \, (n - 1) \oplus_{2/3} f \, (n + 1)}\big) \, 10
\]

\item 1D unbiased random walk
\[
M_2 = 
\big(\tY \, \lambda f n . \, 
\tif{n = 0}{0}{f \, (n - 1) \oplus_{1/2} f \, (n + 1)}\big) \, 10
\]

\item 1D biased (away from 0) random walk
\[
M_3 = 
\big(\tY \, \lambda f n . \, 
\tif{n = 0}{0}{f \, (n - 1) \oplus_{1/3} f \, (n + 2)}\big) \, 10
\]
%While {x > 0} do {x := x-1 \oplus_2/3 x:= x+1}
%M2 = While {x > 0} do {x := x-1 \oplus_2/3 x:= x+2}
\end{compactenum}
\end{example}

\medskip

The term $M_1$ is rankable, terminating in 31 $\tY$-steps on average, and $M_3$ only has a $1/1024$ chance of terminating, but in between, $M_2$ is AST, but isn't $\tY$-PAST, therefore it isn't rankable and Theorem~\ref{thm:rankable implies termination} is insufficient to prove its termination. 
Thus we seek a generalised notion of ranking function so that $M_2$ becomes rankable, and then prove it sound i.e.~rankable in this generalised sense implies AST.

%\paragraph*{Idea} 

\subsection{Antitone ranking functions and antitone strict supermartingales}

\begin{definition}\rm
The definition of \defn{antitone ranking function} $f$ for $M \in \Lambda^0$ is the same as that of ranking function except that in the case of $\tY$-redex, 
we require the existence of an antitone (meaning: $r < r'$ implies $\epsilon(r) \geq \epsilon(r')$) function $\epsilon : \nnReal \to \pReal$ such that the ranking function $f :\mathit{Rch}(M) \to \nnReal$ satisfies
\[f(E[R']) \leq f(E[R]) - \epsilon(f(E[R])) \] 
where $R \to R'$ is the $\tY$-redex rule.
Any closed term for which an antitone ranking function exists is called \defn{antitone rankable}.
\iffalse
Given a ranking function $f$ on $M \in \Lambda^0$, we say that $f$ is \emph{antitone} if there exists an antitone function\footnote{i.e.~$r < r'$ implies $\epsilon(r) \geq \epsilon(r')$} $\epsilon : \nnReal \to \pReal$ such that %the ranking function $f$ satisfies
\[
f(E[R']) \leq f(E[R]) - \epsilon(f(E[R])) 
\]
for all $E[R'] \in \mathit{Rch}(M)$ where $R \to R'$ is the $\tY$-redex rule.
\fi
\end{definition}

Note that antitone ranking functions are actually a generalisation of ranking functions, even though the way we reference them may suggest that they are a type of ranking functions.

\iffalse
\lo{An aside: This CBV $\tY$-rule seems cleaner:
\[
\big(\tY f^{A \to B} \, x^A \, . \, \theta^B \big) \, v \to \theta[(\tY f \, x \, . \, \theta) / f, v / x].
\]
We assume $\tY f^{A \to B} \, x^A \, . \, \theta^B$ is a value.}
\fi

\begin{definition}\rm
Given a probability space $(\Omega, \calF, \mathbb{P})$, and a supermartingale $(Y_n)_{n \geq 0}$ and a stopping time $T$ adapted to filtration $(\calF_n)_{n \geq 0}$,
we say that $(Y_n)_{n \geq 0}$ is an \defn{antitone strict supermartingale w.r.t.~$T$} if for all $n \geq 0$, we have $Y_n \geq 0$, and there exists an antitone function $\epsilon : \nnReal \to \pReal$ satisfying
\(
\expect{Y_{n+1} \mid \calF_n} \leq Y_n - \epsilon (Y_n) \cdot {\bf 1}_{\set{T > n}}
\).
%Any closed term for which an antitone ranking function exists is called \emph{antitone rankable}.
\end{definition}

%\lo{The preceding definition does not place any constraint on the stopping time $T$ (other than that it is w.r.t.~the filtration $(\calF_n)_{n \geq 0}$). However for the definition to make sense, $T$ must be the stopping time $T(s) := \min \set{n \mid Y_n(s) = 0}$.}
%\akr{The definition you gave for an antitone ranking function is incorrect, because the antitone ranking functions are a proper subset of ranking functions. Although we may have been referring to antitone ranking functions as a type of ranking function, they're a generalisation, so they don't actually meet the definition of a ranking function in general.}

\begin{therm}
%\begin{restatable}{therm}{ACStrict}
\label{thm:a-c strict}
Let $(Y_n)_{n \geq 0}$ be an antitone strict supermartingale w.r.t.~stopping time $T$. 
Then $T < \infty$ a.s.
%\end{restatable}
\end{therm}

It is essential in this theorem that $\epsilon$ be defined for all $\mathbb R_{\geq 0}$, not just the values that $(Y_n)_{n \geq 0}$ actually takes (or at least if $(Y_n)_{n \geq 0}$ is uniformly bounded, $\epsilon$ must be positive at the supremum as well as the realized values). 

\begin{proof}
First, as $(Y_n)$ is a supermartingale, $\expect{Y_n} \leq \expect{Y_0}$. 
Therefore
\begin{calculation}
\expect{Y_n \mid T > n}
   \step[=]{rearranging terms}
% \dfrac{\mathbb P[T > n] \, \expect{Y_n \mid T > n} 
% + 
% \mathbb P[T \leq n] \, \expect{Y_n \mid T \leq n} 
% - 
% \mathbb P[T \leq n] \, \expect{Y_n \mid T \leq n}}{\mathbb P[T > n]}
\dfrac{
\begin{array}{l}
\mathbb P[T > n] \, \expect{Y_n \mid T > n} 
+ 
\mathbb P[T \leq n] \, \expect{Y_n \mid T \leq n} 
\\
{} - 
\mathbb P[T \leq n] \, \expect{Y_n \mid T \leq n}
\end{array}
}{\mathbb P[T > n]}
  \step[=]{definition of conditional expectation}
\dfrac{\expect{Y_n} - \mathbb P[T \leq n] \, \expect{Y_n \mid T \leq n}}{\mathbb P[T > n]}
  \step[\leq]{$Y_n \geq 0$ always}
\dfrac{\expect{Y_n}}{\mathbb P[T > n]}
  \step[\leq]{$(Y_n)_n$ is a supermartingale}
\dfrac{\expect{Y_0}}{\mathbb P[T > n]}
\end{calculation}

\noindent\textbf{Claim}:\emph{For all $0 < x \leq 1$, 
\(
\mathbb P[T > B_x] \leq x,
\)
where $B_x = \left \lceil \dfrac{\expect{Y_0}+1}{x \; \epsilon(\expect{Y_0} \, x^{-1})} \right \rceil$ and $\epsilon : \nnReal \to \pReal$ is the antitone function.} 

\smallskip

As the convex hull of $\epsilon$ (the greatest convex function less than or equal to it) satisfies all the conditions assumed of $\epsilon$, in addition to being convex, assume wlog that $\epsilon$ is convex.

Assume for a contradiction that $\mathbb P[T > B_x] > x$.
Then, take $n \leq B_x$. 
We have
\begin{calculation}
\expect{Y_n-Y_{n+1}}
  \step[=]{$\calF_n \subseteq \calF_{n+1}$, def.~\& linearity of cond.~expectation}
\expect{Y_n - \expect{Y_{n+1} \mid \calF_n}}
  \step[\geq]{antitone strict assumption}
\expect{\epsilon(Y_n) \cdot {\bf 1}_{\set{T > n}}}
  \step[=]{definition of expectation conditioning on an event}
\mathbb P[T > n]\ \expect{\epsilon(Y_n) \mid T > n}
  \step[\geq]{Jensen's inequality}
\mathbb P[T > n]\ \epsilon(\expect{Y_n \mid T > n})
  \step[\geq]{proved earlier}
\mathbb P[T > n]\ \epsilon\Big(\dfrac{\expect{Y_0}}{\mathbb P[T > n]}\Big)
  \step[>]{assumption, $\mathbb P[T > n] \geq \mathbb P[T > B_x] > x$}
x \; \epsilon\big(\expect{Y_0} \, x^{-1}\big).
\end{calculation}
Therefore, by a telescoping sum
\[
\expect{Y_{B_x}} 
= \expect{Y_{B_x}-Y_0+Y_0} \leq \expect{Y_0} - B_x \; x \; \epsilon(\expect{Y_0} \, x^{-1})
\leq -1 < 0 
\]
%\lo{$\expect{Y_0 - B_x \; x \; \epsilon(\expect{Y_0} \, x^{-1})}$}
which is a contradiction, therefore the claim must be true, therefore $P[T > n] \to 0$ as $n \to \infty$, therefore $T < \infty$ a.s.
\end{proof}
\begin{example}
Take the probability space $(\Omega, \calF, \mathbb{P})$ where $\Omega$ is the closed interval of reals $[-1, 1]$, $\calF$ the Borel $\sigma$-algebra, and $\mathbb{P}$ the corresponding Lebesgue probability measure.
Let $\omega \in [-1, 1]$. Define random variables $T$ and $(Y_k)_{k \geq 0}$:
\begin{align*}
T(\omega) & := 
\begin{cases}
\min\set{n \in \mathbb{N} \mid \omega > 2^{-n}} & \hbox{if $\omega \in (0, 1]$}\\
\infty & \hbox{otherwise}
\end{cases} 
\\
Y_k(\omega) & := 
\begin{cases}
4-2^{-k} & \hbox{if $\omega \in [-1, 2^{-k}]$ (equivalently $k < T(\omega)$)}\\
0 & \hbox{otherwise}
\end{cases} 
\end{align*}
Plainly, $T$ is a stopping time, and $(Y_n)_{n \geq 0}$ is a supermartingale, adapted to the filtration $(\calF_n)_{n \geq 0}$ where $\calF_n = \calF$ for all $n$. 
In this case, $(Y_n)_{n \geq 0}$ either tends to $4$ as $n \to \infty$, or drops to 0 at some point, with an exponentially decreasing probability. 
With respect to the antitone function $\epsilon(x) = \frac{4-x}{4}$ and stopping time $T$, we have that $(Y_n)_{n \geq 0}$ is an antitone strict supermartingale, except that $\epsilon(4) = 0$, and $T = \infty$ with probability $\frac 1 2$, even though $4$ is larger than any value $(Y_n)_{n \geq 0}$ can actually take, and $\epsilon(Y_n)$ never actually reaches $0$.
%\lo{@Andrew: I refer to the preceding highlighted claim. Did you mean: for all $n, s$, $\epsilon(Y_n(s)) > Y_n(s)$?} \akr{No. This phrasing should be clearer.}
\end{example}

%\changed[lo]{Let $f$ be a ranking function on a closed PPCF term $M$. We say that $M$ is \emph{antitone rankable} by $f$ if the supermartingale $(f(M_n))_{n \geq 0}$ and the stopping time $T_M^{\tY}$, both adapted to the fitration $(\calF_n)_{n \geq 0}$ where $\calF_n := \sigma(M_1, \ldots, M_n)$, are antitone strict.}

\begin{therm}[Antitone ranking function soundness] \label{thm:antitone rankable implies termination}
If a closed PPCF term $M$ is antitone rankable, then $T_M^{\tY} < \infty$ a.s.~(equivalently, $M$ is AST).
\end{therm}
\begin{proof}
As in %Theorem~\ref{thm:basicRankingSoundness}, 
Theorem~\ref{thm:rankable implies termination},
take the probability space $(\entrosp, \Sigma_\entrosp, \mu_\entrosp)$, and define the same r.v.~$T_n, X_n, Y_n, T_M^{\tY}$. 
Thanks to Theorem~\ref{thm:rankable and strict rankable}, $(Y_n)_{n \geq 0}$ is a supermartingale; and because $M$ is now assumed to be antitone rankable, it is an antitone strict supermartingale w.r.t.~stopping time $T_M^{\tY}$. 
Thus, by Theorem~\ref{thm:a-c strict}, $T_M^{\tY} < \infty$ a.s.
\end{proof}

%\paragraph{}
As before, constructing antitone ranking fuctions completely is not necessary, and there is a corresponding notion of an antitone sparse ranking function.

\begin{definition}\rm
Define an \defn{antitone sparse ranking function} on a closed term $M$ to be a partial function $F : Rch(M) \rightharpoonup \mathbb{R}$ such that for some antitone function $\epsilon : \mathbb{R}_{\geq 0} \to \mathbb{R}_{>0}$:
\begin{asparaenum}[(i)]
\item $f(N) \geq 0$ for all $N \in \dom(f)$,
\item $M \in \dom(f)$,
\item for any $N \in \dom(f)$, evaluation of $N$ will eventually reach some $O$ which is either a value or in $\dom(f)$, and $f(N) \geq \mathbb E [f(O) + \epsilon(f(O)) \times \text{the number of $\tY$-reduction steps from $N$ to $O$}]$ (where $f(O)$ is taken to be 0 if $O$ is a value outside of $\dom(f)$).
\end{asparaenum}
\end{definition}

\begin{therm}[Sparse function]
%\begin{restatable}[Sparse function]{therm}{AntitonePartial}  
\label{thm:antitone partial implies rankable}
  Every antitone sparse ranking function is a restriction of an antitone ranking function.
%\end{restatable}
\end{therm}

\begin{proof}
  Take a closed term $M$ and an antitone sparse ranking function $f$ on $M$, with a corresponding antitone function $\epsilon$. Assume wlog that $\epsilon$ is convex (as if it isn't, we can just take its convex hull instead). As in Theorem~\ref{thm:partial implies rankable}, define $f_1 : Rch(M) \rightharpoonup \mathbb R$ by
  \begin{align*}
    f_1(N) &= f(N) \text{ whenever $f(N)$ is defined},\\
    f_1(V) &= 0 \text{ for values $V$ not in the domain of $f$.}
  \end{align*}


  Define $(\nnext(N,s),\_) = \red^n(N,s)$ for the least $n \geq 0$ such that it's in the domain of $f_1$, and $g(N,s) := \left | \{m < n \mid \red^m(N,s) \text{ is of the form } (E[\tY\, \lambda x. N'],s') \} \right |$. 
  The function $\nnext$ is well-defined (i.e.~$n$ is finite) for all $N \in Rch(M)$ by induction on the path from $M$ to $N$, by the third condition on antitone partial ranking functions. Define $f_2(N) := \int_\entrosp f_1(\nnext(N,s)) + \epsilon(f_1(\nnext(N,s))) g(N,s) \, \mu_{\entrosp}(\mathrm d s)$. For any term $N$ where $f$ is defined, $f_2(N) = f(N)$, and the value that $f_2$ would have at $N$ if $f$ were not defined at $N$ is $\leq f(N)$, by the third condition on antitone partial ranking functions. In order to show that $f_2$ is an antitone partial ranking function, it therefore suffices to show that the value that $f_2$ would have had at each term if $f$ were not defined at that term is at least the expectation of $f_2$ after one reduction step (plus $\epsilon(f_2(N))$ if the reduction step is a $tY$-reduction). For any term $N$ which is not of the form $E[R]$ for some $\tY$-redex $R$, this is trivial. If $R$ is a $\tY$-redex, then $\epsilon(f_2(N)) \leq \int_\entrosp \epsilon(f_1(\nnext(N,s)))\, \mu_{\entrosp}(\mathrm d s)$ by the convexity of $\epsilon$, because $n$ is bounded. Therefore, the (total) function $f_2$, which agrees with $f$ on $f$'s domain, is an antitone ranking function on $M$ (with the same function $\epsilon$ if it's convex).
\end{proof}
As a corollary, any term which admits an antitone sparse ranking function terminates almost surely.

\begin{example}[Example~\ref{ex:ac-ranking} revisited]
Programs $M_1$ and $M_2$ are AST. For $M_1$, the sparse ranking function 
\begin{align*}
\big(\tY \, \lambda f n . \, \tif{n=0}{0}{f \, (n-1) \oplus_{3/2} f \, (n+1)}\big) \, \underline x \mapsto 3x + 1
\end{align*}
suffices to prove its termination (and could equivalently be considered an antitone sparse ranking function with the constant antitone function $\epsilon_1(x) = 1$).
\end{example}

\begin{example}[Unbiased random walk]
\label{ex:unbiased random walk}
For $M_2$, define the function $g_2 : \nnReal \to \nnReal$ by $g_2(x) = \ln(x+1) + 1$.
Using shorthand 
$\Theta_2 = \tY \, \lambda f n . \, 
\tif{n = 0}{0}{f \, (n - 1) \oplus_{1/2} f \, (n + 1)}$, 
we can define an antitone sparse ranking function $f_2 : \mathit{Rch}(M_2) \rightharpoonup \nnReal$ 
%with antitone function $\epsilon_2$ defined as follows (for $n \in \mathbb N$):
by
\(
f_2: {\Theta_2} \, n \mapsto 
g_2(n)
\)
and
$0 \mapsto 0$
for $n \in \mathbb N$.
% \begin{align*}
% {\Theta_2} \, n 
% &\mapsto 
% g_2(n)
% \\
% 0 &\mapsto 0.
% \end{align*}
For $n \geq 1$, $\Theta_2 \, n$ reduces in several steps to either $\Theta_2 \, (n-1)$ or $\Theta_2 \, (n+1)$,\footnote{Technically this is not quite correct, because of the distinction between $\underline n + 1$ and $\underline{n + 1}$, but this ranking function can still be made to work by appealing to the Confluent Ranking Theorem~\ref{thm:confluent ranking}, as can the others in this section with similar issues. See Remark~\ref{rem:ex corrected using confluent semantics} for a fuller account.} each with probability $1/2$, with one $\tY$-reduction.
Now
\begin{align*}%\textstyle
g_2(n) - \frac{g_2(n-1) + g_2(n+1)} 2 
  &=  \ln \left(\frac{n+1}{\sqrt{n(n+2)}}\right) 
  =  \frac 1 2 \ln\left(\frac{(n+1)^2}{n(n+2)}\right) \\
  &=  \frac 1 2 \ln\left(1 + \frac 1 {n(n+2)}\right) 
  >  \frac 1 {n(n+2) + 1} \\
  &>  \frac 1 2 \frac 1 {(n+1)^2} + \frac 1 2 \frac 1 {(n+3)^2}
\end{align*}
Moreover $\Theta_2 \, 0$ reduces to $0$ with one $\tY$-reduction with a reduction in $g_2$ of $1$.
Therefore by setting $\epsilon_2(x) = 1 / {(e^{x-1}+1)^2}$, the condition on how much $g_2$ must decrease is met. It is also defined at $M_2 = \Theta_2 \, 10$, and is non-negative, therefore it is an antitone sparse ranking function, and $M_2$ is AST.
\end{example}

\subsection{More challenging examples} 

%\iffalse
Sampling from continuous distributions is an essential feature of statistical probabilistic programming languages. (See e.g.~Church \citep{DBLP:conf/uai/GoodmanMRBT08}, Stan \citep{carpenter2017stan}, Anglican \citep{DBLP:conf/pkdd/TolpinMW15}, Gen \citep{cusumano-towner2019Gen}, Pyro \citep{bingham2019Pyro}, Edward \citep{tran2016edward} and Turing \citep{ge2018Turing}.)
Methods of proving AST of probabilistic computation have been developed for probabilistic programs with discrete distributions (see e.g.~\cite{DBLP:journals/toplas/LagoG19,DBLP:journals/jacm/KaminskiKMO18,DBLP:conf/lics/OlmedoKKM16,DBLP:conf/lics/KobayashiLG19,DBLP:conf/mfcs/KaminskiK15,DBLP:series/mcs/McIverM05}).
To our knowledge, the problem of proving AST of probabilistic functional programs with continuous distribution is new.
%\fi

All of the following examples also have antitone ranking functions.
%, provided in Appendix~\ref{apx:antitone}.

\iffalse
\begin{example}[Continuous random walk]\label{ex:raven complex}
In PPCF we can construct a function whose argument changes by a random amount at each recursive call: $\Theta \, \underline{10}$ where
\[
%\underbrace{\big
\Theta := \tY \, \lambda f x .\ \tif{x \leq 0}{\underline 0}{f(x - \tsample)}
%}_{\Theta} \, 10
\]

For a more complex (not $\tY$-PAST) example, consider the following continuous random walk: $\Xi \, \underline{10}$ where
\[
\Xi := \tY \, \lambda f x .\ \tif{x \leq 0}{\underline 0}{f(x - \tsample + 1/2)} 
\]
\end{example}

\begin{example}[Fair-in-the-limit random walk]
\label{ex:Fair-in-the-limit random walk}\cite[\S 5.3]{DBLP:journals/pacmpl/McIverMKK18}
\[
\big
(\tY\ \lambda f x .\ 
\tif{x \leq 0}{\underline 0}{f(x - 1) \oplus_{\frac{x}{2x+1}} f(x + 1)} \big)
\, \underline{10}
\]
\end{example}

\begin{example}[Non-affine recursion]
\label{ex:non-affine recursion easy}
\[
(\tY \lambda f x. x \oplus_{2/3} f (f (x + 1)))\, \underline 1
\]
\end{example}

\begin{example}[More complex non-affine recursion]
\label{ex:non-affine continuous}
\iffalse
\begin{align*}
& (\tY\, \lambda f x.\, (\lambda e. X[e]) \, \tsample)\, \underline 0 \quad \hbox{where}\\
& X[e] := \tif{e \leq p - x^{-2}}{x}{f^2(x+1) \oplus_e f(x+1)}
\end{align*}
\fi
\[
(\tY\, \lambda f x.\, (\lambda e. X[e]) \, \tsample)\, \underline 0 \quad \hbox{where} \quad
X[e] := \tif{e \leq p - x^{-2}}{x}{f^2(x+1) \oplus_e f(x+1)}
\]
\end{example}

\begin{example}[Higher-order recursion] \label{ex:higher-order recursion}
Consider the higher-order function
$\Xi : (\textsf{R} \to \textsf{R} \to \textsf{R}) \to \textsf{R} \to \textsf{R} \to \textsf{R}$
recursively defined\footnote{Inspired by examples in \cite{DBLP:journals/pacmpl/BurnOR18,DBLP:conf/lics/OngW19}.} by
\[
\Xi := \tY \lambda \varphi \, f^{\textsf{R} \to \textsf{R} \to \textsf{R}} \, s^\textsf{R} \, n^\textsf{R} \,.\, \tif{n \leq 0}{s}{
f \, n \, (\varphi \, f \, s \, (n - 1))
\oplus_p
f \, n \, (\varphi \, f \, s \, (n + 1))
}
\]
\iffalse
\[
\begin{array}{l}
\Xi := \tY \lambda \varphi \, f^{\textsf{R} \to \textsf{R} \to \textsf{R}} \, s^\textsf{R} \, n^\textsf{R} . \\
\qquad\tif{n \leq 0}{s}{
f \, n \, (\varphi \, f \, s \, (n - 1))
\oplus_p
f \, n \, (\varphi \, f \, s \, (n + 1))
}
\end{array}
\]
\fi
For any $F : \textsf{R} \to \textsf{R} \to \textsf{R}$ such that $F\, \underline n\, \underline m$ terminates with no $\tY$ reductions for all $m$ and $n$, $\Xi\, F\, \underline x\, \underline y$ is antitone rankable.
\end{example}
\fi

\begin{example}[Continuous random walk]
\label{ex:raven complex}
Let $\Theta := \tY \, \lambda f x . \tif{x \leq 0}{0}{f(x - \tsample)}$. 
We can construct a sparse ranking function $f$ for $\Theta \, \underline{10}$ as follows:
\begin{align*}
\Theta \, \underline l 
&\mapsto 
l + 2
\\
\tif{\underline l \leq 0}{0}{\Theta \, (\underline l - \tsample)}
&\mapsto
l + 1
\\
\underline 0 &\mapsto 0.
\end{align*}

For a more complex (not $\tY$-PAST) example, consider the following ``continuous random walk'': $\Xi \, \underline{10}$ where
\[
%\underbrace{\big(
\Xi := \tY \, \lambda f x . \tif{x \leq 0}{0}{f(x - \tsample + 1/2)} 
%\big)}_{\Xi} \, 10
\]
Let $g(x) := 2 + \ln(x + 1)$, and let $\epsilon$ be the function specified by
\[
\epsilon(g(x-1/2)) = g(x) - \int_{x-1/2}^{x+1/2}g(y) \, \mathrm d y.
\]
The limit of this as $x \to \infty$ and $g(x+1/2) \to \infty$ is 0, and $\frac {\mathrm d}{\mathrm dx} \epsilon(g(x+1/2)) = \frac 1 {x+1} + \ln(1 - \frac 1 {x + 1/2}) < 0$, and $g$ is monotonic increasing; 
therefore $\epsilon$ is antitone and bounded below by 0.
We define an antitone sparse ranking function by:
\[
\Xi \, \underline l 
\mapsto 
g(l), \qquad 
\underline 0 \mapsto 0
\]

% \begin{align*}
% \Xi \, l 
% &\mapsto 
% g(l)
% \\
% 0 &\mapsto 0
% \end{align*}
The value of $g$ after one $\tY$-reduction step is at least $g(l-1/2)$, therefore the expectation of $\epsilon$ after one $\tY$-reduction step is at most $\epsilon(g(l-1/2)) = g(x) - \int_{x-1/2}^{x+1/2}g(y) \, \mathrm d y$. 
Thus 
\begin{itemize}
\item in case $l > 0$, $g$ decreases by the required amount
\item in case $l \leq 0$, 
\(
g(\Xi \, l) \geq 2 + \ln(1/2) > \ln(\frac{3 \sqrt 3} 2) - 1 = \epsilon(g(0-1/2))
\) 
as well.
\end{itemize}
Hence this is a valid antitone sparse ranking function and the term is AST.
\end{example}

\begin{example}[Fair-in-the-limit random walk] 
\label{ex:Fair-in-the-limit random walk}
\citep[\S 5.3]{DBLP:journals/pacmpl/McIverMKK18}
\[
\underbrace{\big
(\tY \, \lambda f x .\ 
\tif{x \leq 0}{0}{f(x - 1) \oplus_{\frac{x}{2x+1}} f(x + 1)} \big)}_{\Xi} 
\, \underline{10}
\]
To construct an antitone ranking function, we solve the recurrence relation:
% \[
% \left\{
% \begin{array}{rll}
% z_0 &=& 0\\
% n \geq 1, \quad z_n &>& \dfrac{n}{2n + 1} \, z_{n-1} + \dfrac{n+1}{2n + 1} \, z_{n+1}.
% \end{array}
% \right.
% \]
\begin{align*}
z_0 &= 0\\
n \geq 1, \quad z_n &> \textstyle \frac{n}{2n + 1} \, z_{n-1} + \frac{n+1}{2n + 1} \, z_{n+1}.
\end{align*}
For $n > 2$, $z_n = \ln(n-1)$ works. The expected decrease is $\frac 1 2(\ln(1+\frac 1 {(n-1)^2-1}) - \frac 1 {2n+1} \ln(1 + \frac 2 {n-2}))$, and using the fact that $\frac x {x+1} \leq \ln (1+x) \leq x$ for $x > 0$, this is at least $\frac 1 2(\frac 1 {(n-1)^2} - \frac 1 {2n + 1} \frac 2 {n-2}) = \frac {n^2}{2(n-1)^2(2n+1)(n-2)}$, which (again for $n > 2$) is positive and antitone. For $n = 0, 1, 2$, we take $\epsilon$ to be 9/40 (the same as its value at 3), then set $z_2 = 2 \ln 2 - \ln 3 - 1, z_1 = 3 \ln 2 - 2 \ln 3 - 3, z_0 = 4 \ln 2 - 3 \ln 3 - 6$. Some of those values are negative, but it's still bounded below, so by adding a constant offset it can be corrected, and the term is AST.
\end{example}


\begin{example}[Escaping spline]
\label{ex:escaping spline}\cite[\S 5.4]{DBLP:journals/pacmpl/McIverMKK18}
\[
\underbrace{\big
(\tY \, \lambda f x . \,
0 \oplus_{\frac{1}{x+1}} f(x + 1) \big)}_{\Xi} 
\, \underline{10}
\]

In this case, the fact that the ranking function must decrease at each $\tY$-step (in an antitone sparse ranking function) by the expected value of $\epsilon$ not at the current term, but at the next term where the ranking function is defined, is a little harder to deal with, because the variable $x$ can change all the way to $0$ in one step, therefore simply adding a small offset doesn't suffice to compensate for this fact.

Consider the candidate ranking function $\Xi \, \underline n \mapsto n + 1$. For each $n$, $\Xi \, \underline n$ reduces to either $\underline 0$ (with probability $\frac 1 {n + 1}$) or $\Xi \, \underline{n + 1}$, therefore the expected value of the ranking function is $\frac{n(n+2)}{n+1} = n + 1 - \frac 1 {(n+1)^2}$, and the required decrease is $\frac{\epsilon(0) + n \epsilon(n + 2)}{n + 1}$, therefore eventually, the expected decrease isn't enough, whatever the value of $\epsilon(0)$ is.

If instead, we take the ranking function to be defined after the $\tY$-reduction but before the $\tsample$-reduction as well, this can be resolved. Letting $\Theta[n] = \underline 0 \oplus_{\frac 1 n} \Xi \, n$:
\begin{align*}
\Theta[\underline n] &\mapsto n &
\Xi \, \underline{10} & \mapsto 12.
\end{align*}
For each $n$, $\Theta[n]$ reduces to either $0$ or $\Theta[n+1]$, with a $\tY$-reduction only in the latter case, and the condition that this is an antitone sparse ranking function is that $n \geq \frac{(n-1)(n+1)}{n} + \frac{n-1}{n} \epsilon(n+1)$ and $12 \geq 11 + \epsilon(11)$. These are satisfied by setting $\epsilon(x) = \min(1, 1/x)$, therefore this term is AST.
\end{example}

%\medskip

\subsubsection*{Non-affine recursion}

Many of the recent advances in the development of AST verification methods \citep{DBLP:conf/pldi/ChenH20,DBLP:conf/cav/ChakarovS13,DBLP:conf/popl/FioritiH15,DBLP:journals/pacmpl/McIverMKK18,DBLP:conf/aplas/HuangFC18,DBLP:conf/popl/ChatterjeeNZ17,DBLP:journals/pacmpl/AgrawalC018,DBLP:conf/cav/ChatterjeeFG16,DBLP:conf/lics/OlmedoKKM16,DBLP:journals/pacmpl/Huang0CG19} are concerned with loop-based programs.
We can view such loops as tail-recursive programs that are, in particular, \emph{affine recursive}, i.e., 
in each evaluation (or run) of the body of the recursion, recursive calls are made from at most one call site \cite[\S 4.1]{DBLP:journals/toplas/LagoG19}.
(Note that whether a program is affine recursive cannot be checked by just counting textual occurrences of variables.)
Termination analysis of \emph{non-affine recursive} probabilistic programs has not received much attention (with the exception of \citep{BeutnerO21}).
Methods such as those presented in \cite{DBLP:journals/toplas/LagoG19} are explicitly restricted to affine programs, and are unsound otherwise.
By contrast, many probabilistic programming languages allow for richer recursive structures \citep{DBLP:conf/pkdd/TolpinMW15,DBLP:conf/uai/GoodmanMRBT08,DBLP:journals/corr/MansinghkaSP14}.

\begin{example}[Non-affine recursion]
\label{ex:non-affine recursion easy}
Let 
\[
\Xi := \tY \lambda f x. x \oplus_{2/3} f (f (x + 1))
\] 
A suitable sparse ranking function for $\Xi \, \underline 1$ would be $\Xi^n \, \underline i \mapsto 3 \, n$ (for $n \geq 0$), because $\Xi^n \, \underline i$ reduces to either $\Xi^{n+1} \, \underline{i+1}$ or $\Xi^{n-1} \, \underline{i+1}$, with probabilities $1/3$ and $2/3$. The value of $i$ does not actually matter for the progress of this recursion. It is basically another variant of the biased random walk, except that the relevant variable is the number of copies of $\Xi$, instead of a real number in the term.
\end{example}

\begin{example}[More complex non-affine recursion]
\label{ex:non-affine continuous}
Let
\begin{align*}
\Xi & := \tY\, \lambda f x.\, (\lambda e. X[e]) \, \tsample \\
X[e] & := \tif{e \leq p - x^{-2}}{x+1}{f^2(x+1) \oplus_e f(x+1)}
\end{align*}

This example is a little more complex because of the use of a random sample, $e$, as a first class value, which cannot be modelled via discrete distributions. 

We can use the ranking function method (coupled with the solution of linear recurrence relations) to show that provided $p \geq \frac{5 - \sqrt{21}}{2}$, the program $\Xi \, \underline 3$ is AST. 
Consider the edge case, that $p = \frac{5 - \sqrt{21}}{2}$ exactly.

The term $\Xi^n\, \underline x$ (for $n > 0$, $x^{-2} < p$) reduces to either $\Xi^{n-1}\, \underline{x+1}$, $\Xi^n\ \underline{x+1}$ or $\Xi^{n+1}\, \underline{x+1}$, 
with probabilities $p-x^{-2}$, $(1-p+x^{-2})\frac{p-x^{-2}}{2}$ and $(1-p+x^{-2})(1-\frac{p-x^{-2}}{2})$ respectively. 
Let $a(\Xi^n\, \underline x) = n + 2 \, x^{-1}$. 
This is a supermartingale (because the decrease in $2 \, x^{-1}$ as $x$ increases is enough to offset the average increase in $n$), but it does not satisfy the antitone-strict progress condition. 
It does however have a bounded-below variance, so the usual method of using $\ln a$ instead of just $a$ works. 
Calculating the exact amount that $\ln a$ decreases is not necessary, because it can be bounded as follows: 
$a$ changes by at least $1/2$ with probability at least $1/11$ (assuming $x \geq 3$), 
therefore $\ln(a)$ decreases in expectation by at least $\frac{1}{11}(\ln(a+\frac{1}{2}) - \ln(a) -\frac 1 {2a})$, 
using the fact that a linear approximation to $\ln$, applied to $a$, at least doesn't increase, 
then adding the deviation of $\ln$ from its linear approximation $\ln(a) + \frac{x-a}{a}$ 
(and using the fact that the linear approximation is everywhere an overestimate), 
we obtain a sufficiently strong bound on the decrease of $\ln(a)$ that it's an antitone sparse ranking function. 
(It can obviously be extended to $\Xi\, \underline 1$ too, which reduces to $\Xi^n\, \underline 3$ or a value after a bounded number of steps, but that complicates the analysis a little.)
\end{example}

\subsubsection*{Higher-order recursion}

There is an important formalism for constructing (non-random) higher-order recursive functions, viz., \emph{higher-order recursion schemes} (HORS) (see e.g.~\cite{DBLP:conf/lics/Ong06,DBLP:conf/lics/Ong15}).
%(Incidentally the (sparse) ranking function method is just as applicable to the termination analysis of \emph{deterministic} PPCF programs.)
Recently \cite{DBLP:conf/lics/KobayashiLG19} have extended HORS to \emph{probabilistic higher-order recursion schemes} (PHORS), which are HORS augmented with probabilistic (binary) branching $\oplus_p$.
As HORS are in essence the $\lambda \tY$-calculus \citep{DBLP:conf/lics/Statman02} (i.e.~pure simply-typed lambda calculus with recursion, generated from a finite base type), PHORS are definable in PPCF:
(order-$n$) PHORS is encodable as (order-$n$) call-by-name PPCF, but the former is strictly less expressive (because the underlying HORS is not Turing complete). 
For example, the PPCF term in Example~\ref{ex:higher-order recursion} is not definable in PHORS.
%Some interesting PPCF terms such as \Cref{ex:non-affine with continuous distribution} %\refExample{complexExample} 
%cannot be expressed as PHORS.
%\akr{As I removed the referenced example, and I don't even know what a PHORS is, I've just removed this comment too.}

A relevant result here is that the AST problem is decidable for order-1 PHORS (by reduction to the PSPACE-hard solvability of finite systems of polynomial equations with real coefficients; see \citep{DBLP:journals/jacm/EtessamiY09}), but undecidable for PHORS with order greater than 1 \citep{DBLP:conf/lics/KobayashiLG19}.

\begin{example}[Higher-order recursion]
\label{ex:higher-order recursion}
Consider the higher-order function
$\Xi : (\textsf{R} \to \textsf{R} \to \textsf{R}) \to \textsf{R} \to \textsf{R} \to \textsf{R}$
recursively defined by
\[
%\begin{array}{l}
\Xi := \tY \lambda \varphi \, f^{\textsf{R} \to \textsf{R} \to \textsf{R}} \, s^\textsf{R} \, n^\textsf{R} \, . \, 
\tif{n \leq 0}{s}{
f \, n \, (\varphi \, f \, s \, (n - 1))
\oplus_p
f \, n \, (\varphi \, f \, s \, (n + 1))
}
%\end{array}
\]
Let $F : \textsf{R} \to \textsf{R} \to \textsf{R}$ be a function such that $F\ \underline n\ \underline m$ terminates with no $\tY$ reductions for all $m$ and $n$. Then $\Xi\ F\ \underline x\ \underline y$ has the antitone sparse ranking function 
\[
F \, \underline{n_0} \, (F \, \underline{n_1} \, (\dots(\Xi\ F\, \underline x\, \underline n)\dots) \mapsto g_2(n),
\] 
where $g_2$ is as in Example~\ref{ex:unbiased random walk}, using the same antitone function too.

The inequalities required for this to be an antitone partial supermartingale are satisfied with just the same reasoning as in Example~\ref{ex:unbiased random walk}, therefore this term too is antitone rankable.

Again, this is not actually the correct reduction order, in that $F$ should be applied to its argument $n_i$ and reduced to a value before its second argument is expanded, 
but this would complicate the presentation, and this version can be justified by Theorem~\ref{thm:confluent ranking} instead. 
The reduction strategy implied here should be clear enough (assuming that, where it isn't specified, it just matches $\cbv$), but to be more precise, 
let 
\[
r \, (F \, \underline{n_0} \, (\dots(F\, \underline {n_{k-1}}\, X)\dots)) = @_2^k;\cbv(X),
\] 
where $X$ is not a value or of the form $F\ \underline{n_k}\ Z$ for some non-value $Z$. 
Within $X$, there is necessarily a redex at $\cbv(X)$. 
The only conditions that $@_2^k;\cbv(X)$ is also a position of a redex in the whole term are that if the redex is a $\tsample$, 
it is not inside a $\lambda$ that's inside a $\tY$ or on the right of an application, which is true because $\cbv$ never selects a redex inside of a $\lambda$. 
After $n$ reaches $0$, the term is $F \, \underline{n_0} \, (\dots(F\, \underline {n_k} \, \underline x)\dots)$, then the innermost $F$ is evaluated completely in $\cbv$ order, therefore (by assumption) it terminates. 
Because there are no $\tY$-reductions in the evaluation of $F$, it can't reach any other term of the form $F\, \underline{n_k'}\, X$, 
therefore $k$ never changes until this whole subexpression reaches a number, at which point $k$ decreases by 1 and the next $F$ is evaluated.
\end{example}

\iffalse
\antitoneSeemsComplete*

\begin{proof}
If $T$ is bounded by $b$ a.s.~(for $n$ constant), the statement is trivially true by taking $\epsilon$ to be constantly 1, and $Y_n = b - n$.
Otherwise, let $(t_n)_{n \geq 0}$ be defined recursively such that $t_0 = 0$, $t_{n+1} > t_n$ and $\mathbb P[T > t_{n+1}] \leq \frac 1 4 \mathbb P[T > t_n]$.
We will then define a supermartingale $(Y_n)_{n \geq 0}$ and nonrandom sequence $(y_n)_{n \geq 0}$ such that $Y_n = 0$ iff $T < n$, $Y_n = y_n$ iff $T \geq n$, and $y_n \geq 2^k$ for $n \geq t_k$.

The antitone function $\epsilon$ is defined piecewise and recursively in such a way as to force all the necessary constraints to hold:
\begin{align*}
    \text{for }x \in [0,1),\ &\epsilon(x) = 1 \\
    \text{for }x \in [2^k,2^{k+1}),\ &\epsilon(x) = \min \left (\epsilon(2^{k-1}), \frac{2^k}{t_{k+1}-t_k} \right ).
\end{align*}
This ensures that
\begin{itemize}
\item $\epsilon$ is weakly decreasing. 
\item $\epsilon$ is bounded below by 0.
\item For $x \geq 2^k$, $\epsilon(x) \leq \frac{2^k}{t_{k+1}-t_k}$. 
\end{itemize}

The sequence $(y_n)_{n \geq 0}$ is then defined recursively by
\begin{align*}
    y_0 = 2, \quad
    y_{n+1} = (y_n - \epsilon(y_n)) \frac{\mathbb P[T > n]}{\mathbb P[T > n+1]}.
\end{align*}

The fact $y_{t_k} \geq 2^{k+1}$ is proven by induction on $k$. For base case, $2 \geq 2$, as required. For the inductive case $k+1$, we first do another induction to prove that $y_n \geq 2^k$ for all $t_k \leq n \leq t_{k+1}$. The base case of this inner induction follows from the outer induction hypothesis a fortiori. Take the greatest $k$ such that $n > t_k$. By the induction hypothesis, $y_{t_k} \geq 2^k$.

\begin{align*}
    y_n & = y_{t_k} \frac{\mathbb P[T > t_k]}{\mathbb P[T > n]} - \sum_{m=t_k}^{n-1} \epsilon(y_m) \frac{\mathbb P[T > m+1]}{\mathbb P[T > n]} \\
    & \geq \frac{\mathbb P[T > t_k]}{\mathbb P[T > n]} (y_{t_k} - \sum_{m=t_k}^{n-1} \epsilon(y_m)) \\
    & \geq \frac{\mathbb P[T > t_k]}{\mathbb P[T > n]} (y_{t_k} - \sum_{m=t_k}^{n-1} \frac{2^k}{t_{k+1}-t_k}) \\
%\end{align*}
%Allow a page break so that the sim-diagram lines up neatly.
%\begin{align*}
    & = \frac{\mathbb P[T > t_k]}{\mathbb P[T > n]} (y_{t_k} - \frac{2^k (n - t_k)}{t_{k+1}-t_k}) \\
    & \geq \frac{\mathbb P[T > t_k]}{\mathbb P[T > n]} (y_{t_k} - 2^k) \\
    & \geq \frac{\mathbb P[T > t_k]}{\mathbb P[T > n]} (2^{k+1} - 2^k) \\
    & = \frac{\mathbb P[T > t_k]}{\mathbb P[T > n]} 2^k \\
    & \geq 2^k
\end{align*}
as required. Substituting $n = t_{k+1}$ and using the fact that $\frac{\mathbb P[T > t_k]}{\mathbb P[T > t_{k+1}]} > 4$, the same reasoning gives $y_{t_{k+1}} \geq 2^{k+2}$, as required.

The fact $y_n \geq 2^k$ for some $k$ implies that $y_n > 0$ for all $n$, which implies that $Y_n \geq 0$. 
The other condition for $(Y_n)$ to be an antitone-strict supermartingale is
\begin{align*}
    \expect{Y_{n+1} \mid \mathcal F_n} 
    &=  \expect{y_{n+1} \, {\bf 1}_{\set{T \geq n+1}} \mid \mathcal F_n} \\
    &=  y_{n+1} \, \expect{{\bf 1}_{\set{T \geq n+1}} \mid \mathcal F_n} \\ 
    &=  y_{n+1} \, {\bf 1}_{\set{T \geq n}} \textstyle \frac{\mathbb P[T > n+1]}{\mathbb P[T > n]} \\
    &=  (y_n - \epsilon(y_n)) \, {\bf 1}_{\set{T \geq n}} \\
    &= Y_n - \epsilon(y_n) \, {\bf 1}_{\set{T \geq n}}
\end{align*}
therefore $(Y_n)_n$ is an antitone strict supermartingale with respect to $(T,\epsilon)$.
\end{proof}

The assumption that $(\mathcal F_n)_{n \geq 0}$ is the coarsest filtration to which $T$ is adapted is used in the equality between the third and fourth lines here. This condition is the main reason that this proof does not extend directly to a completeness result for antitone ranking functions.
\fi


\subsection{Towards completeness}
Unlike Theorem~\ref{thm:rankable implies termination}, which can only prove termination of $\tY$-PAST terms, this method is capable of proving termination of terms which terminate arbitrarily slowly.

More precisely:
\begin{therm}
\label{thm:towards completeness supermartingales}
For any stopping time $T$ which is almost surely finite, adapted to a filtration $(\calF_n)_n$, then there is a supermartingale $(Y_n)_n$ adapted to $(\calF_n)_n$ and an antitone function $\epsilon$ such that $(Y_n)_n$ is an antitone ranking supermartingale with respect to $T$ and $\epsilon$.
\end{therm}

\begin{proof}
First, take the case where $T$ is bounded by some integer $b$. Setting $\epsilon(x) = 1$ and $Y_n = \max(b-n, 0)$ trivially gives an antitone ranking supermartingale for $T$.

Assume, for the other case, that $T$ is unbounded. Let $f(n) \leq \mathbb P[T < n]$ where $f$ tends to 1 and is concave for arguments $\geq 0$, let $g : [0,1) \to \mathbb N$ be a non-decreasing function such that $g(f(n)) \geq n$ (essentially just taking the inverse of $f$ and filling in the gaps) and let $\epsilon : \mathbb R_{\geq 0} \to \mathbb R_{>0}$ be a convex antitone function $\leq \Delta[f](g(1-e^{-x})-1)$ where $\Delta[f](n) = f(n+1) - f(n)$. Then we can define the supermartingale $(Y_n)_n$ by $Y_n = \mathbb E[-\log(1-f(T-n)) \mid \calF_n]$. Because $T$ is unbounded, $f$ never reaches 1 therefore the logarithm is finite.

In order to show that the expectation $\mathbb E[-\log(1-f(T-n))]$ converges, consider its definition as a Lebesgue integral (using the fact that the argument of the expectation here is non-negative):
\begin{align*}
& \mathbb E[-\log(1-f(T-n))] \\
= & \int_0^\infty \mathbb P[-\log(1-f(T-n)) > x] \, \mathrm d x \\
= & \int_0^\infty \mathbb P[f(T-n) > 1-e^{-x}] \, \mathrm d x \\
\leq & \int_0^\infty \mathbb P[f(T) > 1-e^{-x}] \, \mathrm d x \\
\leq & \int_0^\infty \mu(\{a \mid \mu(\{b \mid T(b) < T(a)\}) > 1-e^{-x}\}) \, \mathrm d x \\
\end{align*}
Let $A_y$ be the set $\{a \mid \mu(\{b \mid T(b) < T(a)\}) > 1-y\}$. Because the predicate $\mu(\{b \mid T(b) < T(a)\}) > 1-y$ is monotonic in $T(a)$, all elements of $A_y$ have higher values of $T$ than all non-elements of $A_y$. Let $a$ be the element of $A_y$ with the minimum value of $T$. Then $1-y < \mu(\{b \mid T(b) < T(a)\}) = \mu(A_y^\complement) = 1 - \mu(A_y)$ therefore $\mu(A_y) < y$. The integral is therefore less than
\begin{align*}
\int_0^\infty e^{-x} \, \mathrm d x < \infty
\end{align*}
therefore $(Y_n)_n$ is well defined.

The sequence is clearly non-negative and adapted to the filtration, so the only condition left to check is the progress condition.
\begin{align*}
& \epsilon(Y_n) \mathbf 1_{T > n} \\
= & \epsilon(\mathbb E[-\log(1-f(T-n)) \mid \calF_n]) \mathbf 1_{T > n} \\
\leq & \mathbb E[\epsilon(-\log(1-f(T-n))) \mathbf 1_{T > n} \mid \calF_n] \\
\leq & \mathbb E[\Delta[f](g(1-e^{\log(1-f(T-n))})-1) \mathbf 1_{T > n} \mid \calF_n] \\
= & \mathbb E[\Delta[f](g(f(T-n))-1) \mathbf 1_{T > n} \mid \calF_n] \\
\leq & \mathbb E[\Delta[f](T-n-1) \mid \calF_n] \\
= & \mathbb E[f(T-n)-f(T-n-1) \mid \calF_n] \\
\leq & \mathbb E[\frac{f(T-n)-f(T-n-1)}{1-f(T-n-1)} \mid \calF_n] \\
\leq & \mathbb E[\log(1-f(T-n-1)) - \log(1-f(T-n)) \mid \calF_n] \\
= & Y_n - \mathbb E[Y_{n+1} \mid \calF_n]
\end{align*}
This relies on the facts that $\epsilon$ is convex, $g(f(n)) \geq n$, and $\Delta[f]$ is antitone for arguments $\geq 0$.

\end{proof}

This construction can be applied to produce antitone ranking functions in most but not all cases. As with the simple version of ranking functions, an antitone ranking function can only exist if every reachable term is AST, because every reachable term must itself be assigned a value and is therefore antitone rankable. An additional restriction is necessary to apply this argument to constructing antitone ranking functions though, to ensure that all the reachable subterms (particularly those only reachable with probability 0, which are less constrained) are antitone rankable with respect to the same antitone function $\epsilon$.

\begin{therm}
\label{thm:towards completeness}
For any closed term $M$, if there is some function $t : \mathbb N \to [0,1]$ that tends to 1 such that for any $N \in \mathit{Rch}(M)$, there exists some $m$ such that the probability that $N$ terminates within $n$ steps is at least $\frac{t(n+m)-t(m)}{1-t(m)}$, then $M$ is antitone rankable.
\end{therm}

\begin{proof}
The same construction as in the previous lemma applies, with the stopping time $T$ being the $\tY$-runtime $T_M^\tY$, but with $f$ being a concave function $\leq t(n)$ instead of $\leq \mathbb P[T < n]$. The definition of $\epsilon$ is identical, and the definition of the ranking function is similar, but taking the $\tY$-runtime starting at $N$ rather than taking the conditional expectation, so it's $\mathbb E[-\log(1-f(T_N^\tY))]$. While the conditional expectation is only defined up to a set of measure 0, this definition is largely equivalent but works for all $N$. \akr{I feel like it's neater to just leave it at that, and imply the proof that the expectation is bounded is the same as in the more abstract case, but the details are a little different.}

Despite the differences between the constructions, the proofs that the ranking function is finite and satisfies the progress condition are generally similar to the proofs in the case of the abstract stopping time.
\end{proof}

This theorem is not able to account for all terms whose antitone rankability is allowed by the theorems proven so far, as it requires not only that all reachable terms terminate, but that they terminate uniformly quickly. In practice this seems likely to include most reasonable programs, but there are still some cases where it doesn't work.

\begin{example} \label{ex:antitone isn't complete}
The number of functions $\mathbb N \to \mathbb N$ is equal to $|\mathbb R|$, therefore by assigning some code and uncurrying, it is possible to define a function $Z : \mathbb R \times \mathbb N \to \mathbb N$ such that $Z(r, \cdot)$ can be any function $\mathbb N \to \mathbb N$ for some $r \in [0,1]$, and it is even possible to do this in such a way that $Z$ is measurable. As PPCF contains every measurable real function as a primitive, it is therefore possible for a PPCF program to randomly pick a function $\mathbb N \to \mathbb N$ so that every such function is possible.

Let $M = (\lambda r m. (\tY \lambda w n. \tif{n < 0}{\underline 0}{w (n-1)}) \underline Z(r, m)) \tsample \lfloor \frac 1 \tsample \rfloor$. This program first picks a random function, then picks an argument for that function from $\mathbb N$, then counts down from the result to 0. Assuming for convenience that $\frac 1 0$ evaluates to $0$, this clearly terminates almost surely, as do all terms reachable from it, but for any candidate $t$, there is some $r$ such that $Z(r, \cdot)$ is much faster growing than $t^{-1}$, therefore the condition for Theorem \ref{thm:towards completeness} is not satisfied for $M$. It turns out this term is not antitone rankable at all. For any $\epsilon$, there is some $f: \mathbb N \to \mathbb N$ sufficiently fast growing that the ranking function value required for each $(\lambda m. (\tY \lambda w n. \tif{n < 0}{\underline 0}{w (n-1)}) \underline f(m)) \underline u$ is at least inversely proportional to the chance of $\lfloor \frac 1 \tsample \rfloor$ evaluating to $\underline u$, therefore $(\lambda m. (\tY \lambda w n. \tif{n < 0}{\underline 0}{w (n-1)}) \underline f(m)) \tsample \lfloor \frac 1 \tsample \rfloor$ as a whole is not rankable w.r.t. that $\epsilon$, and $f$ is $Z(r, \cdot)$ for some $r$, therefore $M$ isn't antitone rankable at all.

This term is therefore a counterexample to the completeness conjecture in a previous version of this paper\cite{thisLics}, but the construction relies crucially on the peculiar property of PPCF that programs can sample an infinite amount of random data at once (in the form of unlimited precision real numbers). The peculiar function $Z$ also plays a crucial role in the construction, but it would be possible to implement it entirely in terms of basic arithmetic operations, so the fact that it is permitted as a primitive should not be taken as a sign that this is an issue unique to an abstract uncomputable language like PPCF.
\end{example}

