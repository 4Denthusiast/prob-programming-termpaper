% !TEX root = main.tex

\section{Introduction}
\label{sec:intro}

Non-probabilistic lambda calculi are generally confluent, i.e.~if a term $A$ reduces to both $B_1$ and $B_2$, there is some $C$ 
to which both $B_1$ and $B_2$ reduce,
so the reduction order mostly doesn't matter. 
In the probabilistic case, this may not be true, because $\beta$-reduction can duplicate $\tsample$s, so the outputs of the copies of the $\tsample$ may be identical or independent, depending on whether the sample is taken before or after $\beta$-reduction. Consider for example the term $(\lambda x. x + x)\, \tsample$, where $\tsample$ reduces to a number chosen uniformly at random from the interval $I = [0,1]$. If it is reduced in call-by-value order, first the $\tsample$ reduces to some number $r$, then the $\beta$ redex is evaluated, then $r$ is added to itself, yielding $\underline{2r}$. If it is reduced in call-by-name order instead, first the $\beta$ redex is reduced, yielding $\tsample + \tsample$, then the $\tsample$s are evaluated independently and added, yielding $\underline{r + r'}$. As $r$ and $r'$ are independent, the distribution of results is triangular, with support $[0,2]$ and peak at $1$, which is different from the uniform distribution of results in the CbV case.

The results obtained by CbV and CbN evaluation differ in a significant way, however, there are some cases where the order of evaluation doesn't matter. For example, in $\tsample + \tsample$, the order in which the $\tsample$s are evaluated doesn't affect the final result, and in $(\lambda x. \tsample)\, \underline 0$, the $\beta$ redex and the $\tsample$ can be evaluated in either order. In order to obtain the desired confluence result, we restrict our attention to a class of reduction strategies that are equivalent to CbV, as the CbN semantics is less expressive.

Even with such a restriction, a trace semantics in the usual style would not be entirely confluent. In the normal sort of trace semantics\cite{borgstrom2016lambda}, there is a sequence of samples, the \emph{trace}, selected at random from a trace space such as $I^{\mathbb N}$, then for every $\tsample$ statement reduction, the next sample from the trace is used in order, so that the samples in the trace are effectively each labelled by a number corresponding to the execution order of the $\tsample$ statements. Consider the evaluation of the term $\tsample - \tsample$ using one of these simple linear traces, $(1, 0, \dots)$. It would reduce to either $1$ or $-1$ depending on the order of evaluation of the $\tsample$s, as that determines which sample from the pre-selected sequence is used for each one. To fix this, rather than pre-selecting samples according to the order they'll be drawn in, they can be labelled according to the position in the term where they'll be used instead.

Further details, including all of the missing proofs, can be found in \cite[\S IV, \S D]{arxiv}.

\subsection{Outline}
First, the syntax of the language PPCF is introduced. Positions are defined as a way of addressing sample statements within a program independently of the reduction order. Next, a version of the reduction relation is presented that is nondeterministic, so that it allows a choice of what order to perform reductions in. The notion of positions is extended to potential positions, for samples which may appear later in the reduction sequence but not necessarily in the initial term. In order to allow potential positions in different reduction sequences to be considered equivalent, a relation $\sim^*$ is defined, and finally, all of these are used to construct a confluent version of the trace semantics, $\Rightarrow$, that is still nondeterministic in reduction order, but does specify the outcome of random choices.
