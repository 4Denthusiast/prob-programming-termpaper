% !TEX root = main.tex
\section{Probabilistic PCF}
\label{sec:PPCF}

\subsection{Syntax of PPCF}

The language PPCF is a call-by-value (CBV) version of PCF with sampling of real numbers from the closed interval $[0,1]$ \citep{Ehrhard2018c,DBLP:journals/pacmpl/EhrhardPT18,DBLP:conf/esop/MakOPW21}.
%\changed[lo]{following \cite{DBLP:conf/esop/MakOPW21} except the score function (\Cref{rem:score})}. 
Types and terms are defined as follows, where $r$ is a real number, $x$ is a variable, $f : \mathbb{R}^n \to \mathbb{R}$ is any measurable function, and $\Gamma$ is an environment:
\begin{align*}
  \text{\em types } A, B &::= \textsf{R}  \mid  A \to B \\
  \text{\em values } V &::= \lambda x.M  \mid  \underline{r} \\
  \text{\em terms } M, N &::= V  \mid  x  \mid  M_1 \, M_2  \mid  \underline{f}(M_1,\dots ,M_n)  \mid  \tY \, M \mid  \tif{M < 0}{N_1}{N_2}  \mid  \tsample
\end{align*}
The typing rules are standard (see Figure~\ref{fig:typing rules}).
Terms are identified up to $\alpha$-equivalence, as usual. 
The set of all terms is denoted $\Lambda$, and the set of closed terms is denoted $\Lambda^0$.

\input{apx-typing-rules}

%\paragraph{}
To define the CBV reduction relation, let \emph{evaluation contexts} be of the form:
\[
  E ::= [\,] \mid E \, M \mid V \, E \mid \underline{f}(\underline r_1,\dots ,\underline r_{k-1}, E, M_{k+1}, \dots, M_n) \mid \tY E \mid \tif{E<0}{M_1}{M_2}
\]
then a term reduces if it is formed by substituting a redex in a context i.e.
\begin{align*}
  E[(\lambda x.M) V] & \to E[M[V/x]] \\
  E[\underline f (\underline r_1, \dots , \underline r_n)] & \to E[\underline{f(r_1,\dots,r_n)}] \\
  E[\tY \lambda x. M] & \to E[\lambda z. M[(\tY \lambda x. M)/x] z]\quad \text{ where $z$ is not free in $M$}\\
  E[\tif{\underline r < 0}{M_1}{M_2}] & \to E[M_1] \text{ where }r < 0 \\
  E[\tif{\underline r < 0}{M_1}{M_2}] & \to E[M_2] \text{ where }r \geq 0 \\
  E[\tsample] & \to E[\underline r] \text{ where } r \in [0,1].
\end{align*}
We write $\to^\ast$ for the reflexive, transitive closure of $\to$.
Every closed term either is a value or reduces to another term.

\subsection{Trace semantics}
\label{sec:sampling semantics}
The relation $\to$ allows $\tsample$ to reduce to any number in $[0,1]$. 
This defines which results are possible, but to specify the exact probabilities, an additional argument is needed to determine the outcome of random samples. Let $ I := [0,1] \subset \mathbb{R} $, and define $\entrosp := I^{\mathbb{N}}$, with the Borel $\sigma$-algebra $\Sigma_\entrosp$. Equivalently, a basis of measurable sets is $\prod_{i=0}^\infty X_i$ where $X_i$ are all Borel and all but finitely many are $I$, and the probability measure $\mu_{\entrosp}$ is given by $\mu_{\entrosp} (\prod_{i=0}^\infty X_i) := \prod_{i=0}^\infty \Leb(X_i)$, \changed[lo]{writing $\Leb$ for the Lebesgue measure.}
\changed[lo]{The maps $\pi_h:\entrosp \to I$ (projecting to the first element) and $\pi_t:\entrosp \to \entrosp$ (popping the first element) are then measurable.}
Following \cite{DBLP:conf/esop/CulpepperC17}, we call the probability space $(\entrosp, \Sigma_\entrosp, \mu_{\entrosp})$ the \emph{entropy space}, and elements of $\entrosp$ \emph{traces}.

Define a \emph{skeleton} to be a term but, instead of having real constants $\underline r$, it has a placeholder $\skeletonPlaceholder$, so that each term $M$ has a skeleton $\mathit{Sk}(M)$, and each skeleton $S$ can be converted to a term $S[r]$ given a vector $r$ of $n$ real numbers to substitute in, where $n$ is the number of occurrences of $\skeletonPlaceholder$ in $S$. 
Following \cite{DBLP:conf/icfp/BorgstromLGS16,DBLP:conf/lics/StatonYWHK16,DBLP:journals/pacmpl/EhrhardPT18}, the $\sigma$-algebra on $\Lambda$ is defined by identifying $\Lambda$ with $\bigcup_{m\geq 0} \big(\mathsf{Sk}_m \times \Real^m \big)$, where $\mathsf{Sk}_m$ is the set of skeletons containing $m$ occurrences of $\skeletonPlaceholder$.
Thus identified, we give $\Lambda$ the countable disjoint union topology of the product topology of the discrete topology on $\mathsf{Sk}_m$ and the standard topology on $\Real^m$, and take the corresponding Borel $\sigma$-algebra.
Note that the connected components of $\Lambda$ have the form $\{S\} \times \Real^m$, with $S$ ranging over $\mathsf{Sk}_m$, and $m$ over $\mathbb{N}$.

\changed[lo]{The one-step reduction of the \emph{trace-based} (or \emph{sampling-style}) \emph{operational semantics} \citep{DBLP:journals/jcss/Kozen81,DBLP:conf/icfp/BorgstromLGS16,DBLP:conf/esop/CulpepperC17}} is given by the function $\red : \Lambda^0 \times \entrosp \to \Lambda^0 \times \entrosp$ where
\begin{equation*}
\red(M,s) := \left\{
    \begin{array}{ll}
        (E[N],s) & \text{if } M = E[R], R \to N \text{ and } R \neq \tsample \\
        (E[\underline{\pi_h(s)}],\pi_t(s)) & \text{if } M = E[\tsample] \\
        (M,s) & \text{if } M \text{ is a value}
    \end{array} \right .
\end{equation*}
%\lo{Both $\to$ and $\red$ are called reduction relation.}

The result after $n$ steps is then simply 
\[
\red^n(M,s) = \underbrace{\red(\ldots\red(}_n M,s)\ldots)
\] 
and the limit $\red^\infty$ can then be defined as a partial function as $\lim_{n \to \infty} \red^n(M,s)$ whenever that sequence becomes constant by reaching a value. A term $M$ terminates for a sample sequence $s$ if the limit $\red^\infty(M,s)$ is defined.

The reduction function is measurable, and the set of values is measurable, therefore the set of $s$ such that $M$ terminates at $s$ within $n$ steps is measurable for any $n$, therefore $\{s \mid \hbox{$M$ terminates at $s$}\}$ is measurable \citep{DBLP:conf/icfp/BorgstromLGS16,DBLP:conf/esop/MakOPW21}. 
We say that a term $M$ is \emph{almost surely terminating} (\emph{AST}) just if $\mu_{\entrosp}(\{s \mid \hbox{$M$ terminates at $s$}\}) = 1$.

\iffalse
\lo{Alternatively, define the \emph{runtime of $M$} to be the random variable 
\[
T_M(s) := 
\begin{cases}
\min \set{n \mid \pi_0(\red^n(M, s)) \textrm{ is a value}} & \hbox{if $\red^\infty(M,s)$ is defined}\\
\infty & \hbox{otherwise}
\end{cases}
\]
Equivalently, we say that $M$ is \emph{almost surely terminating} (AST) if $T_M < \infty$ a.s.; 
and $M$ is \emph{positively almost surely terminating} (PAST) if $\expect{T_M} < \infty$.}
\fi
\begin{example}[Geometric distribution] The term 
\[
(\tY \lambda f n. \tif{\tsample - 0.5 < 0}{n}{f (n+1)} ) \, \underline{0},
\] 
which generates a geometric distribution, terminates on the set $\entrosp \setminus [0.5,1]^\mathbb N$, which has measure 1, therefore it terminates almost surely; whereas 
\(
\tif{\tsample - 0.5 < 0}{\underline 0}{(\tY \lambda x. x) \, \underline 0}
\), 
which terminates on the set $\pi_h^{-1}[[0,0.5]]$, has probability 0.5 of failing to terminate.
\end{example}
%\paragraph{}
%The requirement that $M$ be closed is not important for the proofs of the theorems, but is simply needed to ensure that $M$ reaches a value, rather than a general normal form like $x \, y$. \lo{This can be omitted.}

%\paragraph{}
\begin{remark}
\label{rem:score}
Our definition of AST is equivalent to that given in \cite{DBLP:conf/esop/MakOPW21} (although the program semantics is stated in a slightly different way), except for the presence of a $\tscore$ construct for soft conditioning. 
The $\tscore$ construct is irrelevant to termination except that it fails if its argument is negative, thus allowing computations to fail after finitely many steps. 
If such a thing were added, it would merely require an additional side condition to our main theorems, that no failing term was reachable (or, in the case of the confluent semantics based results, no term where the reduction strategy is not defined is reachable via the reduction strategy unless it's a value).
\end{remark}

\iffalse
\lo{Your operational semantics does not maintain a record of the current weight of the reduction.
A.s.~termination does depend on $\tscore$: see \cite[\S 4.3]{DBLP:conf/esop/MakOPW21}\footnote{\url{https://arxiv.org/abs/2004.03924}}.
I think it important to take the behaviour of $\tscore$ into account;
you should do it as a future task.}
\fi
