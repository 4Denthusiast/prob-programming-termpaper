\documentclass{article}

%% BEGIN {Luke's Macros}
%%
\newif\ifdraft
\drafttrue %% To hide all comments and highlighting, just comment this line out 

\input{Style/comment}

\usepackage[square]{natbib}
\setcitestyle{aysep={}}

\definecolor{oxblue}{RGB}{0,33,71}
\definecolor{oxgold}{HTML}{a0630a}
\usepackage[final,
bookmarks,
bookmarksopen,
colorlinks,
final,
linkcolor=red,
citecolor=oxgold,
pdfstartview=FitH ]{hyperref}
%%
%% END {Luke's Macros}

\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{verbatim}
\newcommand{\tY}{\textsf{Y}}
\newcommand{\tif}[3]{\textsf{if }#1\textsf{ then }#2\textsf{ else }#3}
\newcommand{\tsample}{\textsf{sample}}
\newcommand{\tscore}{\textsf{score}}
\DeclareMathOperator{\red}{red}

\newtheorem{theorem}{Theorem}

\begin{document}

\lo{23 Jan:

\paragraph{Some thoughts about extension to $\mathsf{score}$}

- I still think that the operational semantics (reduction semantics) of SPCF (i.e.~with $\mathsf{score}$) is not problematic. However the notion of a.e.~termination is interesting and would benefit from further thought.

- I would propose that you use the language SPCF defined in \citep{MakOP20b}. They use a big-step reduction semantics. I would sugget that, by contrast, you develop a small-step reduction semantics for it (by a mild adaptation of your $\red : \Lambda \times S \to \Lambda \times S$).

- You will find that your example 
\[
f \, n = n \oplus_{\frac{1}{2}} (\mathsf{score} \, 3 \, ; \, f \, (n+1))
\]
is not definable in SPCF, but a variant (in which the branching probabilities are drawn from the entropy sequence) is. OK, we will need to assume that their $\mathbb{S} := \mathbb{R}^\omega$ is replaced by your $S$.

- Consider the notion of a.e.~termination defined in \citep{MakOP20b}\footnote{\url{https://drive.google.com/open?id=1JzxV0lCkZu4d7szQOzkcKspqqo8u2BP0}} (towards the end of \S 3): a program $s$ is a.e.~terminating if the set of entropy sequences where $s$ does not evaluate to a value has measure zero.
The intuition is that scoring is about model building, and does not by itself ``affect termination''.
}

\bigskip

\lo{22 Jan:
\LaTeX. For references, I recommend using the package {\tt natbib} with {\tt apalike} bibliography style (author-year is more reader-friendly), and placing the references in a separate {\tt .bib} file.
I simply copy-and-paste the bib data from DBLP e.g.~\url{https://dblp.uni-trier.de/pers/hd/o/Ong:C==H=_Luke}.}

\changed[akr]{[Email 22 Dec: I wrote a proof of termination based on ranking supermartingales (a slight strengthening of what you suggested), which is attached (I haven't made a Git repo yet because I don't know where you want it hosted).

I thought some more about termination in the case of a language with a score function. 
It isn't even clear what termination means in that case.
None of the papers I've found include both unbounded scoring and a definition of termination.
\lo{Can you explain your concern? I don't see any problem. See, e.g., the operational semantics in \citep{MakOP20b}; see also \citep{MakOP20a}.} 
You said that the assumption of a.s. termination was often used. 
Do you have any examples where it's used in a context with unbounded scoring, as going with whatever definition that uses is probably most useful?
\lo{See \citep[Sec.~4, pp.~8 \& 9]{Wagner20} -- I am not sure if this addresses your question.}

The case of bounded scoring seems simpler definitionally at least, but still seems like a bad fit for supermartingales, as the martingale property is local in a way scoring isn't. 
I still need to think more about to what extent it can be made to make sense, though.]}

Following your suggestion, I will be providing a criterion for termination of programs in PPCF \citep{DBLP:journals/pacmpl/EhrhardPT18} based on ranking supermartingales. 
As it's more convenient for this proof, a sampling-based semantics \lo{You need to provide reference(s) for sampling-based semantics.} will be used instead of the original distributional semantics. 
I assume some roughly applicable equivalence is proven somewhere, but it doesn't seem that hard anyway.
\lo{Why not provide a proof as an appendix?}

Various theorems about probabilistic programs rely on the assumption that the program terminates almost surely. Proof rules based on relating the program state to supermartingales already exist for first-order imperative programs \citep{DBLP:journals/pacmpl/McIverMKK18}. This paper's contribution is to extend this method to a higher-order setting.

\section{Language definition}
The language SPCF is a simply-typed lambda calculus with sampling of real numbers from $[0,1]$ and unbounded scoring, following \cite{MakOP20b}. Types and terms are defined as follows, where $r$ is a real, $x$ is a variable, $f : \mathbb{R}^n \to \mathbb{R}$ and $\Gamma$ is an environment
\begin{align*}
  & \text{types } A, B ::= \textsf{R}  \mid  A \to B \\
  & \text{values } v ::= x  \mid  \lambda x.s  \mid  \underline{r} \\
  & \text{terms } s, t ::= v  \mid  t_1 t_2  \mid  \underline{f}(s_1,\dots ,s_n)  \mid  \tY s  \mid  \tif{s < 0}{t_1}{t_2}  \mid  \tsample  \mid  \tscore(s)
\end{align*}
\begin{align*}
  \frac{}{\Gamma ; x:A \vdash x:A} \qquad
  \frac{\Gamma ; x:A \vdash s : B}{\Gamma \vdash \lambda x.s : A \to B} \qquad
  \frac{}{\underline{r} : \textsf{R}} \qquad
  \frac{\Gamma \vdash s:A \to B \quad \Gamma \vdash t : A}{\Gamma \vdash s t : B} \\ \\
  \frac{\Gamma \vdash s_1:\textsf{R} \dots \Gamma \vdash s_n:\textsf{R}}{\Gamma \vdash \underline{f}(s_1,\dots,s_n) : \textsf{R}} \ f : \mathbb{R}^n \to \mathbb{R} \qquad
  \frac{\Gamma \vdash s : A \to A}{\Gamma \vdash \tY s : A} \\ \\
  \frac{\Gamma \vdash c : \textsf{R} \quad \Gamma \vdash s_1 : A \quad \Gamma \vdash s_2 : A}{\Gamma \vdash \tif{c < 0}{s_1}{s_2} : A} \qquad
  \frac{}{\Gamma \vdash \tsample : \textsf{R}} \qquad
  \frac{\Gamma \vdash s : \textsf{R}}{\Gamma \vdash \tscore (s) : \textsf{R}}
\end{align*}

To define the reduction relation, let environments be of the form:
\begin{align*}
  E ::= & \, \cdot \mid E t \mid v E \mid \underline{f}(r_1,\dots ,r_{k-1}, E, s_{k+1}, \dots, s_n) \\ & \mid \tY E \mid \tif{E<0}{s_1}{s_2} \mid \tscore (E)
\end{align*}
then a term reduces if it is formed by substituting a redex in an environment i.e.
\begin{align*}
  E[(\lambda x.s) t] & \to E[s[t/x]] \\
  E[\underline f (\underline r_1, \dots , \underline r_n)] & \to E[\underline{f(r_1,\dots,r_n)}] \\
  E[\tY v] & \to E[v (\tY v)] \\
  E[\tif{\underline r < 0}{s_1}{s_2}] & \to E[s_1] \text{ where }r < 0 \\
  E[\tif{\underline r < 0}{s_1}{s_2}] & \to E[s_2] \text{ where }r \geq 0 \\
  E[\tsample] & \to E[\underline r] \text{ where } r \in [0,1] \\
  E[\tscore(\underline r)] & \to E[\underline r]
\end{align*}

\subsection{Sampling semantics}
This version of the reduction relation allows $\tsample$ to reduce to any number in $[0,1]$. To more precisely specify the probabilities, an additional argument is needed to determine the outcome of random samples. Let $ I = [0,1] \subset \mathbb{R} $, and let $S = I^{\mathbb{N}}$, with the Borel $\sigma$-algebra and the measure given by the limit of $1 \gets I \gets I^2 \gets \cdots$, where the maps are the projections that ignore the last element. 
The maps $\pi_h:S \to I, \; \pi_t:S \to S$ popping the first element are then measurable.

The one-step reduction is given by the function $\red : \Lambda \times S \to \Lambda \times S$ where
\begin{equation}
\red(M,s) = \left\{
    \begin{array}{ll}
        (E[N],s) & \text{if } M = E[R], R \to N \text{ and } R \neq \tsample \\
        (E[\underline{\pi_h(s)}],\pi_t(s)) & \text{if } M = E[\tsample] \\
        (M,s) & \text{if } M \text{ normal form}
    \end{array} \right .
\end{equation}

The limit $\red^\infty$ can then be defined as a partial function as $\lim_{n \to \infty} \red^n(M,s)$ whenever that sequence becomes constant by reaching a normal form. A term $M$ terminates for a sample sequence $s$ if the limit $\red^\infty(M,s)$ is defined, and it terminates almost surely if $\mu(\{s \mid M \text{ terminates at } s\}) = 1$.

\paragraph{}
This definition of almost sure termination is equivalent to that given in \citep{MakOP20b}, although the program semantics is stated in a slightly different way. In particular, the argument to $\tscore$ is not relevant to termination (except for the possibility that its argument's evaluation wouldn't terminate).

\subsection{Alternative Semantics}
\akr{This version of the semantics is much more convenient for allowing multiple different reduction orders. I don't currently have a proof of the equivalence of this with the more usual semantics. I expect that that would be somewhat complicated, but not terribly difficult. I don't know whether a semantics like this has already been defined elsewhere. I just thought I'd write it out so you can see it and in case I use it later. If I do end up actually using it I'll write it up nicer, but hopefully this is at least enough for you to understand what I mean.}

Given a term $M$, let $L(M)$ be the set of occurrences in $M$ of variables, $\tsample$ and $\tY$, and let $F(M)$ be the free magma on $L(M)$. \akr{Only the elements with no \tsample{}s except in the rightmost position are used. I'm not sure whether making this explicit in the definition of $F(M)$ makes things more or less clear.} Let $I = [0,1]$ and $S = I^{F(M)}$, with the Borel $\sigma$-algebra and the product measure.

For any reduction \akr{including reductions not included in the definition above, i.e.~out of order reductions} $M \to N$, define a corresponding map $F(M \to N) : F(N) \to F(M)$ induced (as a magma morphism) by the obvious injection along with the replacements
\begin{align*}
F(E[(\lambda x. F[x_i])G[y]] \to E[F(G[y]/x)[G[y_i]]]) (x_i \cdot y) & = y_i\\
F(E[\tY_i F[y]] \to E[F[y_0] (\tY F[y])]) (y_0) & = \tY_i \cdot y
\end{align*}
where $y$ can be any of the things in $L(N)$.

The one-step reduction is given by the function $\red : \Lambda \times S \to \Lambda \times S$ where
\begin{equation}
\red(M,s) = \left\{
    \begin{array}{ll}
        (E[N],s \circ F(E[R] \to E[N])) & \text{if } M = E[R], R \to N \text{ and } R \neq \tsample \\
        (E[\underline{s(\tsample_i)}],s\mid_{F(E[\underline{s(\tsample_i)}])}) & \text{if } M = E[\tsample_i] \\
        (M,s) & \text{if } M \text{ normal form}
    \end{array} \right .
\end{equation}

Essentially the entropy value here contains a pre-selected random value for each possible \tsample-reduction, in a way independent of reduction order, taking into account the possible duplication of \tsample{}s in $\beta$- and \tY-reduction steps.

\section{Ranking functions}
Given a probabilistic program (i.e.~a term $M$), in order to construct a supermartingale to prove its a.s.~termination, a function to assign values to each reachable program state is necessary. Define a ranking function on $M$ to be a measurable function $f:Rch(M) \to \mathbb{R}$ such that
\begin{itemize}
    \item $f(N) \geq 0$ for all $N$
    \item $f(E[\tY N]) \geq 1 + f(E[N(\tY N)])$
    \item $f(E[\tsample]) \geq \int_0^1 f(E[\underline{x}]) \, \mathrm{d}x$
    \item $f(E[R]) \geq f(E[N])$ for any other redex $R$, where $R \to N$.
\end{itemize}

Any term for which a ranking function exists is called ``rankable''.

\section{Supermartingales}

\begin{theorem} \label{rankable implies ast}
  If an SPCF term is rankable, it terminates almost surely.
\end{theorem}
\begin{proof}
Given a term $M$ and a ranking function $f$ for it, define random variables on the probability space $S$ (where $s$ is a random variable) by
\begin{align*}
(M_n,s_n) & = \red^n(M,s) \\
y_0 & = 0 \\
y_{n+1} & = \min \{ k \mid k>y_n, M_k \text{ normal form or of the form } E[\tY N] \}\\
M'_n & = M_{y_n} \\
X_n & = f(M'_n)
\end{align*}
and define a filtration $\mathcal{F}_n = \sigma(M_k, k \leq n)$ (i.e. all the samples used up to step $n$).

The expectation of $f(M_{n+1})$ given $\mathcal{F}_n$ is trivially less than or equal to $f(M_n)$ in the cases that $M_n \neq E[\tsample]$, and in the case of $\tsample$,
\begin{align*}
& \mathbb{E}[f(M_{n+1}) \mid \mathcal{F}_n] \\
= & \mathbb{E}[f(M_{n+1}) \mid M_n = E[\tsample],\, \mathcal{F}_n] \\
= & \mathbb{E}[f(E[\pi_h(s_n)]) \mid \mathcal{F}_n] \\
= & \int_0^1 f(E[\underline x]) \, \mathrm{d} x \qquad & \text{as }s_n\text{ is independent of } \mathcal{F}_n \\
\leq & f(E[\tsample]) \qquad & \text{by assumption on } f \\
= & f(M_n),
\end{align*}
therefore the values of the ranking function $f(M_n)$ are a supermartingale with respect to $\mathcal{F}_n$.

Given $M'_n$, there is some finite bound on the number of reduction steps that can take place from $M'_n$ without a $\tY$-reduction step, because of the type system, therefore $y_{n+1}$ is (conditional on $\mathcal{F}_{y_n+1}$) a bounded stopping time, therefore $\mathbb{E}[f(M_{y_{n+1}}) \mid \mathcal{F}_{y_n+1}] \leq f(M_{y_n+1})$. If $M_{y_n}$ isn't already in normal form, then $M_{y_n} = E[\tY N]$ for some $E, N$, therefore $M_{y_n+1} = N (\tY N)$ and $f(M_{y_n+1}) \leq f(M_{y_n}) - 1$, therefore if $M_{y_n}$ isn't normal form, $\mathbb{E}[X_{n+1} \mid \mathcal{F}_{y_n+1}] \leq X_n - 1$.

Overall, this implies that $\mathbb{E}[X_{n+1}] - \mathbb{E}[X_{n}] \leq -\mathbb P[M_{y_n} \text{not n.f.}]$ therefore as $\mathbb{E}[X_n]$ is bounded below, $\mathbb P[M_{y_n} \text{not n.f.}]$ must tend to 0 as $n \to \infty$. $M_{y_n} \text{n.f.} \Rightarrow M_{y_{n+1}} \text{n.f.}$ therefore $\mathbb P[M_{y_n} \text{not n.f.~for infinitely many values of n}] = \mathbb P[\forall n: M_{y_n} \text{not n.f.}] \leq \inf_n \mathbb P[M_{y_n} \text{not n.f.}] = 0$, therefore $M$ terminates almost surely.
\end{proof}

\section{Constructing Ranking Functions}
Although rankability implies almost sure termination, the converse does not hold in general. For example,
\begin{equation}
\tif{-\tsample < 0}{\underline{0}}{\tY \lambda x. x}
\end{equation}
terminates in 3 steps with probability 1, but isn't rankable because $\tY \lambda x. x$ is reachable, although that has probability 0. Not only is this counterexample a.s.t, it's positively almost surely terminating i.e.~the expected time to termination is finite.

A ranking function can be constructed under the stronger assumptions that, for every $N$ reachable from $M$, the expected number of $\tY$-reduction steps from $N$ to a normal form is finite. In particular, the expected number of $\tY$-reduction steps from each reachable term is a ranking function.

\akr{I don't know whether you'll see this before I actually write the other bit, but I'm planning on giving a more practical way of constructing ranking functions later using a similar technique, which is why this theorem seems relevant.}
\begin{theorem} \label{minimal}
Given a term $M$, the function $f:Rch(M) \to \mathbb R$ given by $f(N) = \mathbb E [\text{the number of }\tY\text{-reduction steps from }N\text{ to a normal form}]$, if it exists, is the least of all possible ranking functions of $M$.
\end{theorem}
\begin{proof}
Let $f$ be the candidate least ranking function defined above, and suppose $g$ is another ranking function such that $f(N) > g(N)$ for some $N \in Rch(M)$. The difference $g - f$ is then a supermartingale (with the same setup as in the proof of Theorem \ref{rankable implies ast}. The restrictions of $f$ and $g$ to $Rch(N)$ have the same properties assumed of $f$ and $g$, so assume w.l.o.g.~that $N=M$.

\akr{TODO: finish this proof. It shouldn't be complicated.}
\end{proof}

\paragraph{}
Even in the case of reasonable simple terms, explicitly constructing a ranking function would be a lot of work, and Theorem \ref{minimal} makes even stronger assumptions than almost sure termination, so it isn't useful for proving it. Take, for example, the term
\begin{align*}
&(\tY \lambda f, n: \\
&\quad \tif{\tsample - 0.5 < 0}{n}{f (n+1)} \\
&) \underline{0}
\end{align*}
which generates a geometric distribution.
    Despite its simplicity, its $Rch$ contains all the terms
\begin{itemize}
    \item $(\tY \lambda f, n: \tif{\tsample - 0.5 < 0}{n}{f (n+1)}) \underline{i}$
    \item $(\lambda f, n: \tif{\tsample - 0.5 < 0}{n}{f (n+1)}) (\tY \lambda f, n: tif{\tsample - 0.5 < 0}{n}{f (n+1)}) \underline{i}$
    \item $(\lambda n: \tif{\tsample - 0.5 < 0}{n}{(\tY \lambda f, m: \tif{\tsample - 0.5 < 0}{n}{f (m+1)}) (m+1)}) \underline{i}$
    \item $\tif{\tsample - 0.5 < 0}{\underline{i}}{(\tY \lambda f, m: \tif{\tsample - 0.5 < 0}{m}{f (m+1)}) (\underline{i}+1)}$
    \item $\tif{\underline r - 0.5 < 0}{\underline{i}}{(\tY \lambda f, m: \tif{\tsample - 0.5 < 0}{m}{f (m+1)}) (\underline{i}+1)}$
    \item $\tif{\underline{r-0.5} < 0}{\underline{i}}{(\tY \lambda f, m: \tif{\tsample - 0.5 < 0}{m}{f (m+1)}) (\underline{i}+1)}$
    \item $\underline{i}$
    \item $(\tY \lambda f, m: \tif{\tsample - 0.5 < 0}{m}{f (m+1)}) (\underline{i}+1)$.
\end{itemize}
\akr{TODO: make this into a diagram with arrows.}
Even in this simple case, defining a ranking function explicitly is awkward because of the number of cases, although in most cases, because the value need only be greater than or equal to that of the next term in sequence, it suffices to take the ranking function as taking only 3 distinct values.


\lo{22 Jan: 
\paragraph{Further directions}

An obvious next step is to extend the result to the $\mathsf{score}$ construct.

The following are highly topical, and could form the basis of an interesting and novel DPhil thesis.
\begin{enumerate}
\item Devise methods for proving (positive) a.s.~termination. 

- For example, develop a type system satisfying the property: if a term is typable then it is (positively) a.s.~terminating.
See~\citep{DBLP:conf/ppdp/BreuvartL18,DBLP:conf/esop/LagoG17}.

- Another approach is to develop algorithms that synthesise ranking supermartingales, following, for example, \citep{DBLP:journals/pacmpl/AgrawalC018}.

\item Develop principles (e.g.~in the form of ``proof rules'') for reasoning about (positively) a.s.~termination, in the style of \citep{DBLP:journals/pacmpl/McIverMKK18}.


\item Design algorithms that synthesise probabilistic invariants (\emph{qua} martingales), \`a la \cite{SchreuderO19}; see also \citep{DBLP:journals/pacmpl/HarkKGK20}.

\end{enumerate}}

\bibliographystyle{apalike}
\bibliography{references}

\iffalse
\begin{thebibliography}{9}
\bibitem{ppcf} Thomas Ehrhard, Michele Pagani, and Christine Tasson. Measurable cones and stable, measurable functions: a model for probabilistic higher-order programming. \emph{PACMPL}, 2(POPL):59:1–59:28, 2018. doi: 10.1145/3158147. URL \href{https://doi.org/10.1145/3158147}{https://doi.org/10.1145/3158147}.
\end{thebibliography}
\fi

\end{document}
