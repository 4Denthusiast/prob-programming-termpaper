\documentclass{article}

%% BEGIN {Luke's Macros}
%%
\newif\ifdraft
\drafttrue %% To hide all comments and highlighting, just comment this line out 

\input{Style/comment}

\usepackage[square]{natbib}
\setcitestyle{aysep={}}

\definecolor{oxblue}{RGB}{0,33,71}
\definecolor{oxgold}{HTML}{a0630a}
\usepackage[final,
bookmarks,
bookmarksopen,
colorlinks,
final,
linkcolor=red,
citecolor=oxgold,
pdfstartview=FitH ]{hyperref}
%%
%% END {Luke's Macros}

\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{verbatim}
\newcommand{\tY}{\textsf{Y}}
\newcommand{\tif}[3]{\textsf{if }#1\textsf{ then }#2\textsf{ else }#3}
\newcommand{\tsample}{\textsf{sample}}
\newcommand{\tscore}{\textsf{score}}
\DeclareMathOperator{\red}{red}

\newtheorem{theorem}{Theorem}

\begin{document}

\lo{23 Jan:

\paragraph{Some thoughts about extension to $\mathsf{score}$}

- I still think that the operational semantics (reduction semantics) of SPCF (i.e.~with $\mathsf{score}$) is not problematic. However the notion of a.e.~termination is interesting and would benefit from further thought.

- I would propose that you use the language SPCF defined in \citep{MakOP20b}. They use a big-step reduction semantics. I would sugget that, by contrast, you develop a small-step reduction semantics for it (by a mild adaptation of your $\red : \Lambda \times S \to \Lambda \times S$).

- You will find that your example 
\[
f \, n = n \oplus_{\frac{1}{2}} (\mathsf{score} \, 3 \, ; \, f \, (n+1))
\]
is not definable in SPCF, but a variant (in which the branching probabilities are drawn from the entropy sequence) is. OK, we will need to assume that their $\mathbb{S} := \mathbb{R}^\omega$ is replaced by your $S$.

- Consider the notion of a.e.~termination defined in \citep{MakOP20b}\footnote{\url{https://drive.google.com/open?id=1JzxV0lCkZu4d7szQOzkcKspqqo8u2BP0}} (towards the end of \S 3): a program $s$ is a.e.~terminating if the set of entropy sequences where $s$ does not evaluate to a value has measure zero.
The intuition is that scoring is about model building, and does not by itself ``affect termination''.
}

\bigskip

\lo{22 Jan:
\LaTeX. For references, I recommend using the package {\tt natbib} with {\tt apalike} bibliography style (author-year is more reader-friendly), and placing the references in a separate {\tt .bib} file.
I simply copy-and-paste the bib data from DBLP e.g.~\url{https://dblp.uni-trier.de/pers/hd/o/Ong:C==H=_Luke}.}

\changed[akr]{[Email 22 Dec: I wrote a proof of termination based on ranking supermartingales (a slight strengthening of what you suggested), which is attached (I haven't made a Git repo yet because I don't know where you want it hosted).

I thought some more about termination in the case of a language with a score function. 
It isn't even clear what termination means in that case.
None of the papers I've found include both unbounded scoring and a definition of termination.
\lo{Can you explain your concern? I don't see any problem. See, e.g., the operational semantics in \citep{MakOP20b}; see also \citep{MakOP20a}.} 
You said that the assumption of a.s. termination was often used. 
Do you have any examples where it's used in a context with unbounded scoring, as going with whatever definition that uses is probably most useful?
\lo{See \citep[Sec.~4, pp.~8 \& 9]{Wagner20} -- I am not sure if this addresses your question.}

The case of bounded scoring seems simpler definitionally at least, but still seems like a bad fit for supermartingales, as the martingale property is local in a way scoring isn't. 
I still need to think more about to what extent it can be made to make sense, though.]}

Following your suggestion, I will be providing a criterion for termination of programs in PPCF \citep{DBLP:journals/pacmpl/EhrhardPT18} based on ranking supermartingales. 
As it's more convenient for this proof, a sampling-based semantics \lo{You need to provide reference(s) for sampling-based semantics.} will be used instead of the original distributional semantics. 
I assume some roughly applicable equivalence is proven somewhere, but it doesn't seem that hard anyway.
\lo{Why not provide a proof as an appendix?}

Various theorems about probabilistic programs rely on the assumption that the program terminates almost surely. Proof rules based on relating the program state to supermartingales already exist for first-order imperative programs \citep{DBLP:journals/pacmpl/McIverMKK18}. This paper's contribution is to extend this method to a higher-order setting.

\section{Language definition}
The language SPCF is a simply-typed lambda calculus with sampling of real numbers from $[0,1]$ and unbounded scoring, following \cite{MakOP20b}. Types and terms are defined as follows, where $r$ is a real, $x$ is a variable, $f : \mathbb{R}^n \to \mathbb{R}$ and $\Gamma$ is an environment
\begin{align*}
  & \text{types } A, B ::= \textsf{R}  \mid  A \to B \\
  & \text{values } v ::= x  \mid  \lambda x.s  \mid  \underline{r} \\
  & \text{terms } s, t ::= v  \mid  t_1 t_2  \mid  \underline{f}(s_1,\dots ,s_n)  \mid  \tY s  \mid  \tif{s < 0}{t_1}{t_2}  \mid  \tsample  \mid  \tscore(s)
\end{align*}
\begin{align*}
  \frac{}{\Gamma ; x:A \vdash x:A} \qquad
  \frac{\Gamma ; x:A \vdash s : B}{\Gamma \vdash \lambda x.s : A \to B} \qquad
  \frac{}{\underline{r} : \textsf{R}} \qquad
  \frac{\Gamma \vdash s:A \to B \quad \Gamma \vdash t : A}{\Gamma \vdash s t : B} \\ \\
  \frac{\Gamma \vdash s_1:\textsf{R} \dots \Gamma \vdash s_n:\textsf{R}}{\Gamma \vdash \underline{f}(s_1,\dots,s_n) : \textsf{R}} \ f : \mathbb{R}^n \to \mathbb{R} \qquad
  \frac{\Gamma \vdash s : A \to A}{\Gamma \vdash \tY s : A} \\ \\
  \frac{\Gamma \vdash c : \textsf{R} \quad \Gamma \vdash s_1 : A \quad \Gamma \vdash s_2 : A}{\Gamma \vdash \tif{c < 0}{s_1}{s_2} : A} \qquad
  \frac{}{\Gamma \vdash \tsample : \textsf{R}} \qquad
  \frac{\Gamma \vdash s : \textsf{R}}{\Gamma \vdash \tscore (s) : \textsf{R}}
\end{align*}

To define the reduction relation, let environments be of the form:
\begin{align*}
  E ::= & \, \cdot \mid E t \mid v E \mid \underline{f}(r_1,\dots ,r_{k-1}, E, s_{k+1}, \dots, s_n) \\ & \mid \tY E \mid \tif{E<0}{s_1}{s_2} \mid \tscore (E)
\end{align*}
then a term reduces if it is formed by substituting a redex in an environment i.e.
\begin{align*}
  E[(\lambda x.s) t] & \to E[s[t/x]] \\
  E[\underline f (\underline r_1, \dots , \underline r_n)] & \to E[\underline{f(r_1,\dots,r_n)}] \\
  E[\tY v] & \to E[v (\tY v)] \\
  E[\tif{\underline r < 0}{s_1}{s_2}] & \to E[s_1] \text{ where }r < 0 \\
  E[\tif{\underline r < 0}{s_1}{s_2}] & \to E[s_2] \text{ where }r \geq 0 \\
  E[\tsample] & \to E[\underline r] \text{ where } r \in [0,1] \\
  E[\tscore(\underline r)] & \to E[\underline r]
\end{align*}

\subsection{Sampling semantics}
This version of the reduction relation allows $\tsample$ to reduce to any number in $[0,1]$. To more precisely specify the probabilities, an additional argument is needed to determine the outcome of random samples. Let $ I = [0,1] \subset \mathbb{R} $, and let $S = I^{\mathbb{N}}$, with the Borel $\sigma$-algebra and the measure given by the limit of $1 \gets I \gets I^2 \gets \cdots$, where the maps are the projections that ignore the last element. 
The maps $\pi_h:S \to I, \; \pi_t:S \to S$ popping the first element are then measurable.

The one-step reduction is given by the function $\red : \Lambda \times S \to \Lambda \times S$ where
\begin{equation}
\red(M,s) = \left\{
    \begin{array}{ll}
        (E[N],s) & \text{if } M = E[R], R \to N \text{ and } R \neq \tsample \\
        (E[\underline{\pi_h(s)}],\pi_t(s)) & \text{if } M = E[\tsample] \\
        (M,s) & \text{if } M \text{ normal form}
    \end{array} \right .
\end{equation}

The limit $\red^\infty$ can then be defined as a partial function as $\lim_{n \to \infty} \red^n(M,s)$ whenever that sequence becomes constant by reaching a normal form. A term $M$ terminates for a sample sequence $s$ if the limit $\red^\infty(M,s)$ is defined, and it terminates almost surely if $\mu(\{s \mid M \text{ terminates at } s\}) = 1$.

\paragraph{}
This definition of almost sure termination is equivalent to that given in \citep{MakOP20b}, although the program semantics is stated in a slightly different way. In particular, the argument to $\tscore$ is not relevant to termination (except for the possibility that its argument's evaluation wouldn't terminate).

\section{Ranking functions}
Given a probabilistic program (i.e.~a term $M$), in order to construct a supermartingale to prove its a.s.~termination, a function to assign values to each reachable program state is necessary. Define a ranking function on $M$ to be a measurable function $f:Rch(M) \to \mathbb{R}$ such that
\begin{itemize}
    \item $f(N) > 0$ for all $N$ not in normal form
    \item $f(N) = 0$ for all $N$ in normal form
    \item $f(E[\tY N]) \geq 1 + f(E[N(\tY N)])$
    \item $f(E[\tsample]) \geq \int_0^1 f(E[\underline{x}]) \, \mathrm{d}x$
    \item $f(E[R]) \geq f(E[N])$ for any other redex $R$, where $R \to N$
\end{itemize}

\section{Supermartingales}

\begin{theorem}
  If an SPCF term has a ranking function, it terminates almost surely.
\end{theorem}
\begin{proof}
Given a term $M$ and a ranking function $f$ for it, define random variables on the probability space $S$ (where $s$ is a random variable) by
\begin{align*}
(M_n,s_n) & = \red^n(M,s) \\
y_0 & = 0 \\
y_{n+1} & = \min \{ k \mid k>y_n, M_k \text{ normal form or of the form } E[\tY N] \}\\
M'_n & = M_{y_n} \\
X_n & = f(M'_n)
\end{align*}
and define a filtration $\mathcal{F}_n = \sigma(M_k, k \leq n)$ (i.e. all the samples used up to step $n$).

\lo{So all the random variables just defined are constant functions. E.g.~$M_n$ is a constant function from $S$ to the measurable space of PPCF terms. \akr{I think we discussed this and it was resolved.}}

The expectation of $f(M_{n+1})$ given $\mathcal{F}_n$ is trivially less than or equal to $f(M_n)$ in the cases that $M_n \neq E[\tsample]$, and in the case of $\tsample$,
\begin{align*}
& \mathbb{E}[f(M_{n+1}) \mid \mathcal{F}_n] \\
= & \mathbb{E}[f(M_{n+1}) \mid M_n = E[\tsample],\, \mathcal{F}_n] \\
= & \mathbb{E}[f(E[\pi_h(s_n)]) \mid \mathcal{F}_n] \\
= & \int_0^1 f(E[\underline x]) \, \mathrm{d} x \qquad & \text{as }s_n\text{ is independent of } \mathcal{F}_n \\
\leq & f(E[\tsample]) \qquad & \text{by assumption on } f \\
= & f(M_n),
\end{align*}
therefore the values of the ranking function $f(M_n)$ are a supermartingale with respect to $\mathcal{F}_n$.

Given $M'_n$, there is some finite bound on the number of reduction steps that can take place from $M'_n$ without a $\tY$-reduction step, because of the type system, therefore $y_{n+1}$ is (conditional on $\mathcal{F}_{y_n+1}$) a bounded stopping time, therefore $\mathbb{E}[f(M_{y_{n+1}}) \mid \mathcal{F}_{y_n+1}] \leq f(M_{y_n+1})$. If $f(M_{y_n}) > 0$, then $M_{y_n} = E[\tY N]$ for some $E, N$, therefore $M_{y_n+1} = N (\tY N)$ and $f(M_{y_n+1}) \leq f(M_{y_n}) - 1$, therefore if $X_n > 0$, $\mathbb{E}[X_{n+1} \mid \mathcal{F}_{y_n+1}] \leq X_n - 1$.

Overall, this implies that $\mathbb{E}[X_{n+1}] - \mathbb{E}[X_{n}] \leq -\mathbb P[X_n > 0]$ therefore as $\mathbb{E}[X_n]$ is bounded below, $\mathbb P[X_n > 0]$ must tend to 0 as $n \to \infty$. $X_n = 0 \Rightarrow X_{n+1} = 0$ therefore $\mathbb P[X_n > 0 \text{ for infinitely many values of n}] = \mathbb P[\forall n: X_n > 0] \leq \inf_n \mathbb P[X_n > 0] = 0$, therefore $M$ terminates almost surely.
\end{proof}


\lo{22 Jan: 
\paragraph{Further directions}

An obvious next step is to extend the result to the $\mathsf{score}$ construct.

The following are highly topical, and could form the basis of an interesting and novel DPhil thesis.
\begin{enumerate}
\item Devise methods for proving (positive) a.s.~termination. 

- For example, develop a type system satisfying the property: if a term is typable then it is (positively) a.s.~terminating.
See~\citep{DBLP:conf/ppdp/BreuvartL18,DBLP:conf/esop/LagoG17}.

- Another approach is to develop algorithms that synthesise ranking supermartingales, following, for example, \citep{DBLP:journals/pacmpl/AgrawalC018}.

\item Develop principles (e.g.~in the form of ``proof rules'') for reasoning about (positively) a.s.~termination, in the style of \citep{DBLP:journals/pacmpl/McIverMKK18}.


\item Design algorithms that synthesise probabilistic invariants (\emph{qua} martingales), \`a la \cite{SchreuderO19}; see also \citep{DBLP:journals/pacmpl/HarkKGK20}.

\end{enumerate}}

\bibliographystyle{apalike}
\bibliography{references}

\iffalse
\begin{thebibliography}{9}
\bibitem{ppcf} Thomas Ehrhard, Michele Pagani, and Christine Tasson. Measurable cones and stable, measurable functions: a model for probabilistic higher-order programming. \emph{PACMPL}, 2(POPL):59:1–59:28, 2018. doi: 10.1145/3158147. URL \href{https://doi.org/10.1145/3158147}{https://doi.org/10.1145/3158147}.
\end{thebibliography}
\fi

\end{document}
